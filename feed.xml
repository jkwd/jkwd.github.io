<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://jkwd.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://jkwd.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-04T09:19:47+00:00</updated><id>https://jkwd.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Chess DE Project</title><link href="https://jkwd.github.io/blog/2025/chess-de-project/" rel="alternate" type="text/html" title="Chess DE Project"/><published>2025-04-03T00:00:00+00:00</published><updated>2025-04-03T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2025/chess-de-project</id><content type="html" xml:base="https://jkwd.github.io/blog/2025/chess-de-project/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>This is a data engineering project that ingests data from Chess.com API into DuckDB, transforms the data using dbt on DuckDB and visualising the results on a Streamlit dashboard.</p> <h2 id="architecture">Architecture</h2> <p>The data engineering project stack contains the following:</p> <ol> <li><a href="https://dlthub.com/">dltHub</a>: Ingestion Layer to load the data into the data warehouse</li> <li><a href="https://dagster.io/">Dagster</a>: To schedule and orchestrate the DAGs</li> <li><a href="https://www.postgresql.org/">Postgres</a>: To store and persist Dagster details</li> <li><a href="https://duckdb.org/">DuckDB</a>: Data Warehouse</li> <li><a href="https://streamlit.io/">Streamlit</a>: Dashboard Layer</li> </ol> <h2 id="architecture-diagram">Architecture Diagram</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-03-chess-de-project/1-480.webp 480w,/assets/img/2025-04-03-chess-de-project/1-800.webp 800w,/assets/img/2025-04-03-chess-de-project/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-03-chess-de-project/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="project-structure">Project Structure</h2> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.
├── chess_dagster
│   ├── chess_dbt
│   ├──   ├── dbt_project.yml
│   ├──   ├── models/
│   ├──   ├── tests/
│   ├──   ├── udf/
│   ├──   ├── ...
│   ├── chess_dlt
│   ├──   ├── .dlt/
│   ├──   ├── __init__.py
│   ├──   ├── data_contracts.py
│   ├── chess_etl
│   ├──   ├── assets_dbt.py
│   ├──   ├── assets_dlt.py
│   ├──   ├── definitions.py
│   ├──   ├── resources.py
│   ├── dagster.yaml
│   ├── Dockerfile_dagster
│   ├── Dockerfile_user_code
│   ├── profiles.yml
│   ├── pyproject.toml
│   ├── workspace.yaml
├── data
│   ├── chess.duckdb
│   ├── ...
├── streamlit_dashboard
│   ├── app.py
│   ├── Dockerfile
│   └── requirements.txt
├── .env.example
├── docker-compose-dashboard.yml
├── docker-compose.yml
├── Makefile
└── README.md
</code></pre></div></div> <h2 id="running-chess-dashboard">Running Chess Dashboard</h2> <h3 id="run-locally">Run locally</h3> <p>To run locally, you’ll need:</p> <ol> <li><a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git">git</a></li> <li><a href="https://github.com/">Github account</a></li> <li><a href="https://docs.docker.com/engine/install/">Docker</a></li> <li><a href="https://docs.docker.com/compose/install/">Docker Compose</a></li> </ol> <p>Clone the repo, create a <code class="language-plaintext highlighter-rouge">.env</code> file and run the following commands to start the data pipeline:</p> <ol> <li><code class="language-plaintext highlighter-rouge">git clone https://github.com/jkwd/chess_dashboard.git</code></li> <li><code class="language-plaintext highlighter-rouge">cd chess_dashboard</code></li> <li><code class="language-plaintext highlighter-rouge">make init</code> to create an <code class="language-plaintext highlighter-rouge">.env</code> file from <code class="language-plaintext highlighter-rouge">.env.example</code></li> <li>Edit the <code class="language-plaintext highlighter-rouge">CHESS_USERNAME</code> in the <code class="language-plaintext highlighter-rouge">.env</code> file to your username</li> <li><code class="language-plaintext highlighter-rouge">make up</code> to build and start the docker container</li> <li>Go to <code class="language-plaintext highlighter-rouge">http://localhost:3000</code> to view the Dagster UI</li> <li><a href="#running-dagster-job">Materialize all assets</a></li> <li>Go to <code class="language-plaintext highlighter-rouge">http://localhost:8501</code> to view the Streamlit Dashboard</li> <li><code class="language-plaintext highlighter-rouge">make down</code> to stop the containers</li> </ol> <h3 id="github-codespaces">Github Codespaces</h3> <ol> <li>Fork/Clone <code class="language-plaintext highlighter-rouge">https://github.com/jkwd/chess_dashboard.git</code> to your own Repository</li> <li>Open in Codespaces</li> <li><code class="language-plaintext highlighter-rouge">make init</code> to create an <code class="language-plaintext highlighter-rouge">.env</code> file from <code class="language-plaintext highlighter-rouge">.env.example</code></li> <li>Edit the <code class="language-plaintext highlighter-rouge">CHESS_USERNAME</code> in the <code class="language-plaintext highlighter-rouge">.env</code> file to your username</li> <li><code class="language-plaintext highlighter-rouge">make up</code> to build and start the docker container</li> <li>Find the forwarded addresses in <code class="language-plaintext highlighter-rouge">PORTS</code> section of the Code Editor</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-03-chess-de-project/2-480.webp 480w,/assets/img/2025-04-03-chess-de-project/2-800.webp 800w,/assets/img/2025-04-03-chess-de-project/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-03-chess-de-project/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li>Go to Forwarded address for port <code class="language-plaintext highlighter-rouge">3000</code> to view the Dagster UI</li> <li><a href="#running-dagster-job">Materialize all assets</a></li> <li>Go to Forwarded address for port <code class="language-plaintext highlighter-rouge">8501</code> to view the Streamlit Dashboard</li> <li><code class="language-plaintext highlighter-rouge">make down</code> to stop the containers</li> <li>Stop/Delete Codespaces when you are done</li> </ol> <h3 id="running-dagster-job">Running Dagster Job</h3> <p>Click on Assets Tab on the top</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-03-chess-de-project/3-480.webp 480w,/assets/img/2025-04-03-chess-de-project/3-800.webp 800w,/assets/img/2025-04-03-chess-de-project/3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-03-chess-de-project/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Click on View global asset ineage at the top right of the page</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-03-chess-de-project/4-480.webp 480w,/assets/img/2025-04-03-chess-de-project/4-800.webp 800w,/assets/img/2025-04-03-chess-de-project/4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-03-chess-de-project/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Click on Materialize All</p> <h1 id="implementation">Implementation</h1> <h2 id="dagster-as-an-orchestrator">Dagster as an Orchestrator</h2> <p>Taking it directly from the docs, Dagster is an open source data orchestrator built for data engineers, with integrated lineage, observability, a declarative programming model, and best-in-class testability.</p> <p>There are many components to Dagster, but for this project we mainly focus on the following:</p> <ol> <li>Asset: The logical unit of data, e.g. table, dataset, ML model. This forms the nodes in the lineage graph. In this project, the assets are the dlt asset and the dbt asset.</li> <li>Resource: External dependencies such as APIs, databases, or anything outside of Dagster. In this project, the resources are DuckDB, dlt and dbt.</li> <li>Jobs: A subset of Assets. E.g. <code class="language-plaintext highlighter-rouge">some_job_1</code> can contain assets <code class="language-plaintext highlighter-rouge">A, B, C</code> and <code class="language-plaintext highlighter-rouge">some_job_2</code> can contain assets <code class="language-plaintext highlighter-rouge">W, X, Y, Z</code>.</li> <li>Schedule: A way to automate jobs/assets at a given interval (e.g. run everyday at 0000 UTC)</li> <li>Definitions: The top-level construct of the Dagster project which contains references to all the objects, e.g. Asset, Resources, Schedules, Jobs, etc.</li> </ol> <h2 id="duckdb-as-the-data-warehouse">DuckDB as the Data Warehouse</h2> <p>In simple terms, DuckDB is the online analytical processing (OLAP) version of SQLite. It is easy to install with a <code class="language-plaintext highlighter-rouge">pip install duckdb</code> and its completely embedded within the host system. It is free, fast, portable and has lots of features. It is simple and perfect for a single-node project like this.</p> <h2 id="ingestion-using-dltdagster">Ingestion using dlt+dagster</h2> <p><a href="https://dlthub.com/">dlt</a> allows us to load data from source system to a destination system using python.</p> <p>There are 4 main components to dlt:</p> <ol> <li><a href="https://dlthub.com/docs/general-usage/source">Source</a>: The group of resources we plan to get the data from. E.g. API endpoint or Postgres DB</li> <li><a href="https://dlthub.com/docs/general-usage/resource">Resource</a>: A function that yields the data</li> <li><a href="https://dlthub.com/docs/general-usage/destination">Destination</a>: The location we want the data to land. E.g. S3, Snowflake, DuckDB</li> <li><a href="https://dlthub.com/docs/reference/explainers/how-dlt-works">Pipeline</a>: The main building block of dlt which orchestrates the loading of data from your source into your destination in three discrete steps <ol> <li>Extracts data from the source to the hard drive</li> <li>Inspects and normalizes your data and computes a schema compatible with your destination. E.g. <code class="language-plaintext highlighter-rouge">{"items": {"id": 1}}</code> will become <code class="language-plaintext highlighter-rouge">items__id</code>. You can control the normalization phase and apply data schema contracts.</li> <li>Loads the data into the destination and run schema migrations if necessary</li> </ol> </li> </ol> <h3 id="configuring-the-source">Configuring the Source</h3> <p>A source can consist of a group of resources. So let’s start with the resource first:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chess_dagster/chess_dlt/__init__.py
</span>
<span class="nd">@dlt.resource</span><span class="p">(</span><span class="n">write_disposition</span><span class="o">=</span><span class="sh">"</span><span class="s">replace</span><span class="sh">"</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">PlayersGames</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">player_games</span><span class="p">(</span><span class="n">username</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Generator</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
    <span class="sh">"""</span><span class="s">
    Yields player</span><span class="sh">'</span><span class="s">s `username` games.
    Args:
        username: str: Player username to retrieve games for.
    Yields:
        Generator[Any, Any, Any]: A generator that return a list of games for a player.
    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">_get_player_archives</span><span class="p">(</span><span class="n">username</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">:</span>
        <span class="sh">"""</span><span class="s">
        Returns url to game archives for a specified player username.
        Args:
            username: str: Player username to retrieve archives for.
        Yields:
            List: List of player archive data.
        </span><span class="sh">"""</span>

        <span class="n">data</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">https://api.chess.com/pub/player/</span><span class="si">{</span><span class="n">username</span><span class="si">}</span><span class="s">/games/archives</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">.</span><span class="nf">json</span><span class="p">().</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">archives</span><span class="sh">"</span><span class="p">,</span> <span class="p">[])</span>

    <span class="c1"># get archives in parallel by decorating the http request with defer
</span>    <span class="nd">@dlt.defer</span>
    <span class="k">def</span> <span class="nf">_get_games</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]:</span>
        <span class="sh">"""</span><span class="s">
        Returns games of the specified player username from the given archive url.
        Args:
            url: str: URL to the archive to retrieve games from in the format https://api.chess.com/pub/player/{username}/games/{YYYY}/{MM}
        Yields:
            List: List of player</span><span class="sh">'</span><span class="s">s games data.
        </span><span class="sh">"""</span>
        <span class="n">logger</span><span class="p">.</span><span class="nf">info</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Getting games from </span><span class="si">{</span><span class="n">url</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">games</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">).</span><span class="nf">json</span><span class="p">().</span><span class="nf">get</span><span class="p">(</span><span class="sh">"</span><span class="s">games</span><span class="sh">"</span><span class="p">,</span> <span class="p">[])</span>
            <span class="k">return</span> <span class="n">games</span>  <span class="c1"># type: ignore
</span>
        <span class="k">except</span> <span class="n">requests</span><span class="p">.</span><span class="n">HTTPError</span> <span class="k">as</span> <span class="n">http_err</span><span class="p">:</span>
            <span class="c1"># sometimes archives are not available and the error seems to be permanent
</span>            <span class="k">if</span> <span class="n">http_err</span><span class="p">.</span><span class="n">response</span><span class="p">.</span><span class="n">status_code</span> <span class="o">==</span> <span class="mi">404</span><span class="p">:</span>
                <span class="k">return</span> <span class="p">[]</span>
            <span class="k">raise</span>
        <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">err</span><span class="p">:</span>
            <span class="n">logger</span><span class="p">.</span><span class="nf">error</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Unexpected error: </span><span class="si">{</span><span class="n">err</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
            <span class="k">raise</span>


    <span class="n">archives</span> <span class="o">=</span> <span class="nf">_get_player_archives</span><span class="p">(</span><span class="n">username</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">url</span> <span class="ow">in</span> <span class="n">archives</span><span class="p">:</span>
        <span class="c1"># the `url` format is https://api.chess.com/pub/player/{username}/games/{YYYY}/{MM}
</span>
        <span class="c1"># get the filtered archive
</span>        <span class="k">yield</span> <span class="nf">_get_games</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
</code></pre></div></div> <p>Here we have 1 resource <code class="language-plaintext highlighter-rouge">player_games</code> which gets the games of the player.</p> <p>Where we have configured 2 things:</p> <ol> <li><code class="language-plaintext highlighter-rouge">write_disposition="replace"</code>: This means that every time we get new data, we will replace the entire table.</li> <li><code class="language-plaintext highlighter-rouge">columns=PlayersGames</code>: This is where we apply a data schema contract during using <a href="https://docs.pydantic.dev/latest/">Pydantic</a> the normalize phase of the pipeline to ensure that the API returns the columns that we expect and in the right data type.</li> </ol> <p>Once we have the resource data, we can plug it into the source as such:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chess_dagster/chess_dlt/__init__.py
</span>
<span class="nd">@dlt.source</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">chess</span><span class="sh">"</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">source</span><span class="p">(</span><span class="n">username</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="nf">return </span><span class="p">(</span>
        <span class="nf">player_games</span><span class="p">(</span><span class="n">username</span><span class="o">=</span><span class="n">username</span><span class="p">)</span>
    <span class="p">)</span>
</code></pre></div></div> <p>As mentioned earlier, a <code class="language-plaintext highlighter-rouge">dlt.source</code> consist of a group or resources. So if there is another resource then we just need to add it into the return statement tuple.</p> <p>The dagster asset created from the source and resource will have the name of <code class="language-plaintext highlighter-rouge">dlt_&lt;source_def_name&gt;_&lt;resource_def_name&gt;</code>. So in the case of the project it will be identified as <code class="language-plaintext highlighter-rouge">dlt_source_player_games</code>. If you remember when configuring <code class="language-plaintext highlighter-rouge">@dlt.source(name="chess")</code> we have the additional <code class="language-plaintext highlighter-rouge">name</code> parameter, this overwrites the source function name. So it will finally resolve to <code class="language-plaintext highlighter-rouge">dlt_chess_player_games</code> to be referenced by other downstream assets.</p> <p>Now that we have the source and resources done, let’s integrate dlt with dagster.</p> <h3 id="integrating-dlt-with-dagster">Integrating dlt with dagster</h3> <p>You can follow this <a href="https://docs.dagster.io/integrations/embedded-elt/dlt">guide</a> to integrate dagster+dlt.</p> <p>This requires:</p> <ol> <li>Creating the dagster resource for dlt (Not to be confused with dlt resource)</li> <li>Creating of the dlt asset</li> <li>Setting the dlt asset and dagster resource for dlt into the dagster definition</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chess_dagster/chess_etl/resources.py
</span>
<span class="kn">from</span> <span class="n">dagster_embedded_elt.dlt</span> <span class="kn">import</span> <span class="n">DagsterDltResource</span>

<span class="n">dlt_resource</span> <span class="o">=</span> <span class="nc">DagsterDltResource</span><span class="p">()</span>
</code></pre></div></div> <p>Configuring the dagster resource for dlt is as simple as the 2 lines above. This resource will then be used in the Dagster definition. We will come back to the Dagster definition in the later section after configuring the dbt asset and resources as well.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chess_dagster/chess_etl/assets_dlt.py
</span>
<span class="nd">@dlt_assets</span><span class="p">(</span>
    <span class="n">dlt_source</span><span class="o">=</span><span class="nf">source</span><span class="p">(</span>
        <span class="n">username</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">CHESS_USERNAME</span><span class="sh">"</span><span class="p">)</span>
    <span class="p">),</span>
    <span class="n">dlt_pipeline</span><span class="o">=</span><span class="nf">pipeline</span><span class="p">(</span>
        <span class="n">pipeline_name</span><span class="o">=</span><span class="sh">"</span><span class="s">chess_pipeline</span><span class="sh">"</span><span class="p">,</span>
        <span class="n">destination</span><span class="o">=</span><span class="n">destinations</span><span class="p">.</span><span class="nf">duckdb</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">'</span><span class="s">CHESS_DB</span><span class="sh">'</span><span class="p">)),</span> <span class="c1"># The path to the .duckdb file
</span>        <span class="n">dataset_name</span><span class="o">=</span><span class="n">SCHEMA_RAW</span><span class="p">,</span> <span class="c1"># This is the table schema in duckdb.
</span>    <span class="p">),</span>
    <span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">chess</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># This is the table catalog in duckdb.
</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">chess_dlt_assets</span><span class="p">(</span><span class="n">context</span><span class="p">:</span> <span class="n">AssetExecutionContext</span><span class="p">,</span> <span class="n">dlt</span><span class="p">:</span> <span class="n">DagsterDltResource</span><span class="p">):</span>
    <span class="k">yield</span> <span class="k">from</span> <span class="n">dlt</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">)</span>
</code></pre></div></div> <p>The above code creates the dlt asset. dlt allow us to just focus on getting the data into the required format. If you noticed, the creation and insert/overwrite/deletion of schema and table are all handled by dlt.</p> <p>In DuckDB, the table details will be as follows when the data has been loaded given that <code class="language-plaintext highlighter-rouge">SCHEMA_RAW='chess_data_raw'</code>:</p> <table> <thead> <tr> <th>table_catalog</th> <th>table_schema</th> <th>table_name</th> </tr> </thead> <tbody> <tr> <td>chess</td> <td>chess_data_raw</td> <td>player_games</td> </tr> </tbody> </table> <h2 id="transformation-using-dbtdagster">Transformation using dbt+dagster</h2> <p><a href="https://docs.getdbt.com/docs/introduction">dbt</a> is a transformation workflow that allows you to modularize and centralize your analytics code, while also providing your data team with guardrails typically found in software engineering workflows. It allows engineers to transform data in the warehouse more effectively and its the T in the ELT framework.</p> <p>There are many components to dbt, but for this project we mainly focus on the following:</p> <ol> <li>Models: SQL/python queries that define data transformations</li> <li>Tests: Ensure data quality by validating on the models</li> <li>Documentation: Documentation of the table and columns as well as providing the data lineage</li> </ol> <h3 id="configuring-the-dbt-project">Configuring the dbt project</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># dbt_project.yml</span>

<span class="na">name</span><span class="pi">:</span> <span class="s1">'</span><span class="s">chess_dbt'</span>
<span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">1.0.0'</span>

<span class="na">profile</span><span class="pi">:</span> <span class="s1">'</span><span class="s">chess_dbt'</span>

<span class="na">model-paths</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">models"</span><span class="pi">]</span>
<span class="na">seed-paths</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">seeds"</span><span class="pi">]</span>
<span class="na">test-paths</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">tests"</span><span class="pi">]</span>
<span class="na">analysis-paths</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">analysis"</span><span class="pi">]</span>
<span class="na">macro-paths</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">macros"</span><span class="pi">]</span>

<span class="na">target-path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">target"</span>
<span class="na">clean-targets</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="s2">"</span><span class="s">target"</span>
    <span class="pi">-</span> <span class="s2">"</span><span class="s">dbt_modules"</span>
    <span class="pi">-</span> <span class="s2">"</span><span class="s">logs"</span>

<span class="na">require-dbt-version</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">&gt;=1.0.0"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">&lt;2.0.0"</span><span class="pi">]</span>

<span class="na">vars</span><span class="pi">:</span>
  <span class="na">username</span><span class="pi">:</span> <span class="s2">"</span><span class="s">{{env_var('CHESS_USERNAME')}}"</span>


<span class="na">models</span><span class="pi">:</span>
  <span class="na">chess_dbt</span><span class="pi">:</span>
    <span class="na">materialized</span><span class="pi">:</span> <span class="s">table</span>
    <span class="na">staging</span><span class="pi">:</span>
      <span class="na">materialized</span><span class="pi">:</span> <span class="s">view</span>

</code></pre></div></div> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># profiles.yml</span>

<span class="na">chess_dbt</span><span class="pi">:</span>
  <span class="na">target</span><span class="pi">:</span> <span class="s">dev</span>
  <span class="na">outputs</span><span class="pi">:</span>
    <span class="na">dev</span><span class="pi">:</span>
        <span class="s">...</span>
    <span class="na">ci</span><span class="pi">:</span>
        <span class="s">...</span>
    <span class="na">prod</span><span class="pi">:</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">duckdb</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s2">"</span><span class="s">{{</span><span class="nv"> </span><span class="s">env_var('CHESS_DB')</span><span class="nv"> </span><span class="s">}}"</span>
      <span class="na">threads</span><span class="pi">:</span> <span class="m">1</span>
      <span class="na">module_paths</span><span class="pi">:</span>
        <span class="pi">-</span> <span class="s2">"</span><span class="s">{{</span><span class="nv"> </span><span class="s">env_var('DAGSTER_APP')</span><span class="nv"> </span><span class="s">}}/chess_dbt/udf"</span>
      <span class="na">plugins</span><span class="pi">:</span>
        <span class="c1"># Custom module in the lib directory that defines SQL UDFs written in Python at the start of</span>
        <span class="c1"># the dbt run</span>
        <span class="pi">-</span> <span class="na">module</span><span class="pi">:</span> <span class="s">my_custom_functions</span>

</code></pre></div></div> <p>Above are the configurations for the <code class="language-plaintext highlighter-rouge">dbt_project.yml</code> and <code class="language-plaintext highlighter-rouge">profiles.yml</code>.</p> <h3 id="using-python-udfs">Using python UDFs</h3> <p>In the <code class="language-plaintext highlighter-rouge">profiles.yml</code> you may notice something less familiar under the <code class="language-plaintext highlighter-rouge">module_paths</code> and <code class="language-plaintext highlighter-rouge">plugins</code>. DuckDB allows us to register Python UDFs which can then be used as a function in our SQL models. So we create the UDF in <code class="language-plaintext highlighter-rouge">my_custom_functions.py</code> file located at the specified module_paths.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chess_dagster/chess_dbt/udf/my_custom_functions.py
</span>
<span class="kn">from</span> <span class="n">duckdb</span> <span class="kn">import</span> <span class="n">DuckDBPyConnection</span>

<span class="kn">from</span> <span class="n">dbt.adapters.duckdb.plugins</span> <span class="kn">import</span> <span class="n">BasePlugin</span>
<span class="kn">from</span> <span class="n">dbt.adapters.duckdb.utils</span> <span class="kn">import</span> <span class="n">TargetConfig</span>

<span class="kn">import</span> <span class="n">chess.pgn</span>
<span class="kn">from</span> <span class="n">io</span> <span class="kn">import</span> <span class="n">StringIO</span>
<span class="kn">import</span> <span class="n">chess</span>

<span class="k">def</span> <span class="nf">pgn_to_fens_udf</span><span class="p">(</span><span class="n">pgn</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
    <span class="sh">"""</span><span class="s">Takes in a PGN and go move by move to get the FEN of the board at each move.
    Returns a list of fen strings.

    Args:
        pgn (str): pgn of the game

    Returns:
        arr (list[str]): fen strings of the board at each move
    </span><span class="sh">"""</span>
    <span class="n">pgn_header</span> <span class="o">=</span> <span class="n">pgn</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="se">\n\n</span><span class="sh">'</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">pgn_moves</span> <span class="o">=</span> <span class="n">pgn</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">'</span><span class="se">\n\n</span><span class="sh">'</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">Chess960</span><span class="sh">'</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pgn_header</span><span class="p">:</span>
        <span class="n">pgn</span> <span class="o">=</span> <span class="n">pgn_moves</span>

    <span class="n">arr</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">game</span> <span class="o">=</span> <span class="n">chess</span><span class="p">.</span><span class="n">pgn</span><span class="p">.</span><span class="nf">read_game</span><span class="p">(</span><span class="nc">StringIO</span><span class="p">(</span><span class="n">pgn</span><span class="p">)).</span><span class="nf">game</span><span class="p">()</span>
    <span class="n">board</span> <span class="o">=</span> <span class="n">game</span><span class="p">.</span><span class="nf">board</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">move</span> <span class="ow">in</span> <span class="n">game</span><span class="p">.</span><span class="nf">mainline_moves</span><span class="p">():</span>
        <span class="n">board</span><span class="p">.</span><span class="nf">push</span><span class="p">(</span><span class="n">move</span><span class="p">)</span>
        <span class="n">fen</span> <span class="o">=</span> <span class="n">board</span><span class="p">.</span><span class="nf">fen</span><span class="p">()</span>
        <span class="n">arr</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">fen</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">arr</span>

<span class="c1"># The python module that you create must have a class named "Plugin"
# which extends the `dbt.adapters.duckdb.plugins.BasePlugin` class.
</span><span class="k">class</span> <span class="nc">Plugin</span><span class="p">(</span><span class="n">BasePlugin</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">configure_connection</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">conn</span><span class="p">:</span> <span class="n">DuckDBPyConnection</span><span class="p">):</span>
        <span class="n">conn</span><span class="p">.</span><span class="nf">create_function</span><span class="p">(</span><span class="sh">"</span><span class="s">pgn_to_fens_udf</span><span class="sh">"</span><span class="p">,</span> <span class="n">pgn_to_fens_udf</span><span class="p">)</span>
</code></pre></div></div> <p>Above is an example of how we can configure the the UDF and in the SQL model, we can do something like below to use it:</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span>
<span class="n">pgn_to_fens_udf</span><span class="p">(</span><span class="s1">'some_pgn'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fens</span>
<span class="k">from</span> <span class="n">some_table</span>
</code></pre></div></div> <p>Technically, dbt has released python models which would have allowed us to just create the model in python instead of using UDF with SQL. However by doing this, we may restrict ourselves unintentionally. As dbt is a more SQL-first framework, some features such as dbt unit-tests are only <a href="https://docs.getdbt.com/docs/build/unit-tests#before-you-begin">supported with SQL models</a>.</p> <h3 id="integrating-dbt-with-dagster">Integrating dbt with dagster</h3> <p>You can follow this <a href="https://docs.dagster.io/integrations/libraries/dbt/dbt-core">guide</a> to integrate dagster+dbt.</p> <p>This requires:</p> <ol> <li>Creating the dagster resource for dbt</li> <li>Creating of the dbt asset in Dagster</li> <li>Setting the dbt asset and dagster resource for dbt into the dagster definition</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chess_dagster/chess_etl/resources.py
</span>
<span class="kn">from</span> <span class="n">dagster_dbt</span> <span class="kn">import</span> <span class="n">DbtCliResource</span>
<span class="kn">from</span> <span class="n">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span> <span class="n">os</span>

<span class="n">HOME_DIR</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">HOME</span><span class="sh">"</span><span class="p">)</span>

<span class="n">dbt_project_dir</span> <span class="o">=</span> <span class="nc">Path</span><span class="p">(</span><span class="n">__file__</span><span class="p">).</span><span class="nf">joinpath</span><span class="p">(</span><span class="sh">"</span><span class="s">..</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">..</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">chess_dbt</span><span class="sh">"</span><span class="p">).</span><span class="nf">resolve</span><span class="p">()</span>
<span class="n">dbt_resource</span> <span class="o">=</span> <span class="nc">DbtCliResource</span><span class="p">(</span><span class="n">project_dir</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="nf">fspath</span><span class="p">(</span><span class="n">dbt_project_dir</span><span class="p">),</span>
                              <span class="n">profiles_dir</span><span class="o">=</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">join</span><span class="p">(</span><span class="n">HOME_DIR</span><span class="p">,</span> <span class="sh">"</span><span class="s">.dbt</span><span class="sh">"</span><span class="p">),</span>
                              <span class="n">global_config_flags</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">--log-format-file</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">text</span><span class="sh">"</span><span class="p">],</span>
                              <span class="n">target</span><span class="o">=</span><span class="sh">"</span><span class="s">prod</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># If DAGSTER_DBT_PARSE_PROJECT_ON_LOAD is set, a manifest will be created at run time.
# Otherwise, we expect a manifest to be present in the project's target directory.
</span><span class="k">if</span> <span class="n">os</span><span class="p">.</span><span class="nf">getenv</span><span class="p">(</span><span class="sh">"</span><span class="s">DAGSTER_DBT_PARSE_PROJECT_ON_LOAD</span><span class="sh">"</span><span class="p">):</span>
    <span class="n">dbt_manifest_path</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">dbt_resource</span><span class="p">.</span><span class="nf">cli</span><span class="p">(</span>
            <span class="p">[</span><span class="sh">"</span><span class="s">--quiet</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">parse</span><span class="sh">"</span><span class="p">],</span>
            <span class="n">target_path</span><span class="o">=</span><span class="nc">Path</span><span class="p">(</span><span class="sh">"</span><span class="s">target</span><span class="sh">"</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="p">.</span><span class="nf">wait</span><span class="p">()</span>
        <span class="p">.</span><span class="n">target_path</span><span class="p">.</span><span class="nf">joinpath</span><span class="p">(</span><span class="sh">"</span><span class="s">manifest.json</span><span class="sh">"</span><span class="p">)</span>
    <span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">dbt_manifest_path</span> <span class="o">=</span> <span class="n">dbt_project_dir</span><span class="p">.</span><span class="nf">joinpath</span><span class="p">(</span><span class="sh">"</span><span class="s">target</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">manifest.json</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>Setting up the dbt resources is not as straightforward as dlt’s. Like any other dbt projects, we may need to specify the path to the <code class="language-plaintext highlighter-rouge">dbt_project.yml</code> and <code class="language-plaintext highlighter-rouge">profiles.yml</code>.</p> <p>In addition to the 2 files, Dagster also expects the dbt <code class="language-plaintext highlighter-rouge">manifest.json</code> to be present. The manifest contains all the dbt model, tests, macros, etc and it’ll be used by Dagster to create the respective Dagster Assets and also display them on the lineage graph in the UI. We have <code class="language-plaintext highlighter-rouge">DAGSTER_DBT_PARSE_PROJECT_ON_LOAD</code> in our <code class="language-plaintext highlighter-rouge">.env</code> file to give us the flexibility to provide our own manifest file or to parse one at “runtime”.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chess_dagster/chess_etl/assets_dbt.py
</span>
<span class="kn">from</span> <span class="n">dagster</span> <span class="kn">import</span> <span class="n">AssetExecutionContext</span>
<span class="kn">from</span> <span class="n">dagster_dbt</span> <span class="kn">import</span> <span class="n">DbtCliResource</span><span class="p">,</span> <span class="n">dbt_assets</span>

<span class="kn">from</span> <span class="n">chess_etl.resources</span> <span class="kn">import</span> <span class="n">dbt_manifest_path</span>


<span class="nd">@dbt_assets</span><span class="p">(</span><span class="n">manifest</span><span class="o">=</span><span class="n">dbt_manifest_path</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">chess_dbt_assets</span><span class="p">(</span><span class="n">context</span><span class="p">:</span> <span class="n">AssetExecutionContext</span><span class="p">,</span> <span class="n">dbt</span><span class="p">:</span> <span class="n">DbtCliResource</span><span class="p">):</span>
    <span class="k">yield</span> <span class="k">from</span> <span class="n">dbt</span><span class="p">.</span><span class="nf">cli</span><span class="p">([</span><span class="sh">"</span><span class="s">build</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">--target</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">prod</span><span class="sh">"</span><span class="p">],</span> <span class="n">context</span><span class="o">=</span><span class="n">context</span><span class="p">).</span><span class="nf">stream</span><span class="p">()</span>
</code></pre></div></div> <p>Using the <code class="language-plaintext highlighter-rouge">manifest.json</code> and the <code class="language-plaintext highlighter-rouge">DbtCliResource</code>, we can now define our Dagster dbt asset. We can specify the dbt command that we want in <code class="language-plaintext highlighter-rouge">dbt.cli()</code>.</p> <h2 id="dagster-definitions-to-integrate-dltdbt-into-dagster">Dagster definitions to integrate dlt+dbt into Dagster</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># chess_dagster/chess_etl/definitions.py
</span>
<span class="kn">from</span> <span class="n">dagster</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Definitions</span><span class="p">,</span>
    <span class="n">ScheduleDefinition</span><span class="p">,</span>
    <span class="n">define_asset_job</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="n">chess_etl.assets_dlt</span> <span class="kn">import</span> <span class="n">chess_dlt_assets</span>
<span class="kn">from</span> <span class="n">chess_etl.assets_dbt</span> <span class="kn">import</span> <span class="n">chess_dbt_assets</span>
<span class="kn">from</span> <span class="n">chess_etl.resources</span> <span class="kn">import</span> <span class="n">dlt_resource</span><span class="p">,</span> <span class="n">dbt_resource</span>


<span class="n">all_assets_job</span> <span class="o">=</span> <span class="nf">define_asset_job</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">all_assets_job</span><span class="sh">"</span><span class="p">)</span>

<span class="n">daily_refresh_schedule</span> <span class="o">=</span> <span class="nc">ScheduleDefinition</span><span class="p">(</span>
    <span class="n">job</span><span class="o">=</span><span class="n">all_assets_job</span><span class="p">,</span> <span class="n">cron_schedule</span><span class="o">=</span><span class="sh">"</span><span class="s">0 0 * * *</span><span class="sh">"</span>
<span class="p">)</span>

<span class="c1"># Must be last
</span><span class="n">defs</span> <span class="o">=</span> <span class="nc">Definitions</span><span class="p">(</span>
    <span class="n">assets</span><span class="o">=</span><span class="p">[</span><span class="n">chess_dlt_assets</span><span class="p">,</span> <span class="n">chess_dbt_assets</span><span class="p">],</span>
    <span class="n">resources</span><span class="o">=</span><span class="p">{</span>
        <span class="sh">"</span><span class="s">dlt</span><span class="sh">"</span><span class="p">:</span> <span class="n">dlt_resource</span><span class="p">,</span>
        <span class="sh">"</span><span class="s">dbt</span><span class="sh">"</span><span class="p">:</span> <span class="n">dbt_resource</span><span class="p">,</span>
    <span class="p">},</span>
    <span class="n">schedules</span><span class="o">=</span><span class="p">[</span><span class="n">daily_refresh_schedule</span><span class="p">],</span>
    <span class="n">jobs</span><span class="o">=</span><span class="p">[</span><span class="n">all_assets_job</span><span class="p">]</span>
<span class="p">)</span>
</code></pre></div></div> <p>In the definitions, we will define the 2 resources and assets. We can also create a Job and Schedule for that Job. Everything will be part of the <code class="language-plaintext highlighter-rouge">Definitions()</code> that will be used to power the Dagster app.</p> <h2 id="deploying-dagster-on-docker">Deploying Dagster on Docker</h2> <p>You can follow this <a href="https://docs.dagster.io/guides/deploy/deployment-options/docker">guide</a> and this <a href="https://github.com/dagster-io/dagster/tree/master/examples/deploy_docker">github</a> to deploy the project on Dagster</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-03-chess-de-project/5-480.webp 480w,/assets/img/2025-04-03-chess-de-project/5-800.webp 800w,/assets/img/2025-04-03-chess-de-project/5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-03-chess-de-project/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Dagster allows us to seperate the user code from the system code. This allows for seperation of concerns and any crashes from the user code will not crash Dagster. Each user code repository and the Dagster system can run on their own python environment as well which reduces the dependencies of each other.</p> <p>You may view the following code in the links provided to set up Dagster on Docker:</p> <ul> <li><a href="https://github.com/jkwd/chess_dashboard/blob/main/chess_dagster/Dockerfile_dagster">Dockerfile_dagster</a></li> <li><a href="https://github.com/jkwd/chess_dashboard/blob/main/chess_dagster/Dockerfile_user_code">Dockerfile_user_code</a></li> <li><a href="https://github.com/jkwd/chess_dashboard/blob/main/docker-compose.yml">docker-compose.yml</a></li> <li><a href="https://github.com/jkwd/chess_dashboard/blob/main/chess_dagster/workspace.yaml">workspace.yaml</a></li> <li><a href="https://github.com/jkwd/chess_dashboard/blob/main/chess_dagster/dagster.yaml">dagster.yaml</a></li> </ul> <h2 id="streamlit-dashboard">Streamlit Dashboard</h2> <p>Once the data has been populated, we can view the results in the streamlit dashboard under <code class="language-plaintext highlighter-rouge">http://localhost:8501/</code>.</p> <h2 id="ci-checks">CI Checks</h2> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="na">name</span><span class="pi">:</span> <span class="s">Docker CI Workflow</span>

<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">main"</span> <span class="pi">]</span>
  <span class="na">pull_request</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span> <span class="pi">[</span> <span class="s2">"</span><span class="s">main"</span> <span class="pi">]</span>

<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">run-ci-tests</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>

    <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Checkout code</span>
      <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Create .env file</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">cp .env.example .env</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Check docker-compose</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">docker compose version</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Check docker-compose format</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">docker compose -f docker-compose.yml config</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install Make</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">sudo apt-get install make</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Build the docker compose images</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">make build</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run python lint</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">make lint-python</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run SQL lint</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">make lint-sql</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run pytest</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">make pytest</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run dbt unit test</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">make dbt-unit-test</span>

    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run e2e</span>
      <span class="na">run</span><span class="pi">:</span> <span class="s">make run</span>

  <span class="na">generate-dbt-docs</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">run-ci-tests</span>

    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Checkout code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">print working directory</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">pwd</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">list directory</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">ls -l</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dbt</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">pip3 install dbt-duckdb==1.9.0</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Verify dbt</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">dbt --version</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">dbt parse</span>
        <span class="na">working-directory</span><span class="pi">:</span> <span class="s">./chess_dagster/chess_dbt</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">CHESS_USERNAME</span><span class="pi">:</span> <span class="s">magnuscarlsen</span>
        <span class="na">run </span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">dbt parse --profiles-dir .. --project-dir . --target ci</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">generate dbt docs</span>
        <span class="na">working-directory</span><span class="pi">:</span> <span class="s">./chess_dagster/chess_dbt</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">CHESS_USERNAME</span><span class="pi">:</span> <span class="s">magnuscarlsen</span>
        <span class="na">run </span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">dbt docs generate --profiles-dir .. --project-dir . --empty-catalog --no-compile --target ci</span>
          <span class="s">cd target</span>
          <span class="s">mkdir ${{ github.workspace }}/docs</span>
          <span class="s">cp *.json *.html ${{ github.workspace }}/docs</span>
          <span class="s">ls -ltra ${{ github.workspace }}/docs</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Upload</span><span class="nv"> </span><span class="s">pages</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">artifact"</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/upload-pages-artifact@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">${{ github.workspace }}/docs</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Zip</span><span class="nv"> </span><span class="s">artifact"</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">zip -jrq docs.zip ${{ github.workspace }}/docs</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Upload</span><span class="nv"> </span><span class="s">artifact</span><span class="nv"> </span><span class="s">for</span><span class="nv"> </span><span class="s">deployment</span><span class="nv"> </span><span class="s">job"</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/upload-artifact@v4</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">docs</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">docs.zip</span>

  <span class="c1"># Deploy to Github pages</span>
  <span class="na">deploy-to-github-pages</span><span class="pi">:</span>
    <span class="c1"># Add a dependency to the build job</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">generate-dbt-docs</span>

    <span class="c1"># Grant GITHUB_TOKEN the permissions required to make a Pages deployment</span>
    <span class="na">permissions</span><span class="pi">:</span>
      <span class="na">pages</span><span class="pi">:</span> <span class="s">write</span> <span class="c1"># to deploy to Pages</span>
      <span class="na">id-token</span><span class="pi">:</span> <span class="s">write</span> <span class="c1"># to verify the deployment originates from an appropriate source</span>

    <span class="c1"># Deploy to the github-pages environment</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">github-pages</span>
      <span class="na">url</span><span class="pi">:</span> <span class="s">${{ steps.deployment.outputs.page_url }}</span>

    <span class="c1"># Specify runner + deployment step</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Deploy to GitHub Pages</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">deployment</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/deploy-pages@v4</span> <span class="c1"># or the latest "vX.X.X" version tag for this action</span>

</code></pre></div></div> <p>For CI, we use Github Actions to perform the checks and publish dbt docs for reference:</p> <ol> <li>Lint python using ruff</li> <li>Lint SQL using sqlruff</li> <li>Run pytests for python based unit tests</li> <li>Run dbt unit tests</li> <li>Run Dagster Job end-to-end to ensure everything works (Job is relatively fast)</li> <li>Generate dbt docs</li> <li>Publish dbt docs to github pages (You can view the generated dbt docs <a href="https://johnkohwd.com/chess_dashboard">here</a>)</li> </ol> <p>Step 1-5 are being run on the docker container to ensure consistency in the results.</p>]]></content><author><name></name></author><category term="project"/><category term="data_engineering"/><category term="ingestion"/><category term="transformation"/><category term="docker"/><summary type="html"><![CDATA[Chess Dashboard Data Engineering Project using Dagster, DuckDB, dlt, dbt]]></summary></entry><entry><title type="html">Full vs incremental load</title><link href="https://jkwd.github.io/blog/2025/full-vs-incremental-load/" rel="alternate" type="text/html" title="Full vs incremental load"/><published>2025-03-20T00:00:00+00:00</published><updated>2025-03-20T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2025/full-vs-incremental-load</id><content type="html" xml:base="https://jkwd.github.io/blog/2025/full-vs-incremental-load/"><![CDATA[<h1 id="introduction">Introduction</h1> <p>In this <a href="/blog/2025/oltp-vs-olap/">article</a>, we explored Online Transaction Processing (OLTP) database vs an Online analytical processing (OLAP) database and their purposes. We covered the idea that OLTP are meant for daily operations such as e-commerce transactions, where there is large volume of single transactions happening at any point in time, while OLAP are meant for analytical use cases.</p> <p>Although we can technically still perform business-oriented queries on OLTP databases accepting the fact that it’s slower, its also not recommended as we do not want to overload the database and risk having an outage. The OLTP database is what powers the webapp/app UI that the end users interface with and bringing the OLTP database down will be detrimental to the company.</p> <p>Therefore to perform business-oriented queries, we would take the data in the OLTP databases and ingest/load them into an offline area. This can be in the form of a datalake such as S3 or into a OLAP database such as a data warehouse where there is no additional stress on the operational databases during heavy queries.</p> <h1 id="ingestion">Ingestion</h1> <p>There are 2 main type of data ingestion strategy, Full Load and Incremental Load. Each of them have their set of pros and cons and we will discuss about them in detail below. Another key point is that ingestions generally involves a source (e.g. API, database, filesystem) and a destination (e.g. database, filesystem).</p> <h2 id="full-load">Full load</h2> <p>In a full load strategy, as the name suggests, the entire source data is read and loaded to the destination. If the destination already contains existing data, it will be deleted and replaced with the latest records that are coming in.</p> <p>This method is usually used if the data we are processing is small enough, or during the initial setup and followed by an incremental load subsequently (more details later), or to refresh the data warehouse to the latest data. Full load can be time consuming as we are reading the entire data from the source. This also incur a sudden burst of stress for the source system especially if the data we are ingesting is large.</p> <p>A Full Load should be done preferably when we know the traffic to the app and transaction to the source database is low so to avoid spike in resource consumption on the system.</p> <h3 id="pros">Pros</h3> <ol> <li>Complexity: Easy to setup a full load from the source system to the destination system. A naive way to think is a CTRL-C + CTRL V (overwrite existing data)</li> <li>Data consistency: Data in the destination is consistent with the source system</li> </ol> <h3 id="cons">Cons</h3> <ol> <li>Ingestion Speed: Slow for large dataset as it requires a full scan on the source data</li> <li>Stress on source system: Resource consumption (e.g. CPU) can spike during a full load especially if the data is large and may impact other applications that are running.</li> </ol> <h2 id="incremental-load">Incremental Load</h2> <p>In an incremental load strategy, only the updated/newest data from the source system are loaded to the destination system. This results in lesser data being transferred between them which improves speed and reduces stress.</p> <p>This method is useful for large data in the source system where doing a full load is not ideal, or if we wish to process data in smaller time intervals (e.g. hourly as we only need to process the new/updated data from the past hour).</p> <p>Incremental Load can also be otherwise known as Change Data Capture (CDC) or Delta Load.</p> <h3 id="pros-1">Pros</h3> <ol> <li>Ingestion Speed: Faster than Full Load since we are only loading new/updated data.</li> <li>Stress on source system: Less stress as we are only getting the new/updated data instead of the whole data table everytime.</li> <li>Frequency of ingestion: Allows for flexibility of more frequent ingestion due to the above 2 reasons.</li> <li>Scalability: Useful for large datasets.</li> </ol> <h3 id="cons-1">Cons</h3> <ol> <li>Complexity: Harder to implement. Requires additional columns (e.g. timestamp column), or other change data capture mechanism to reconcile the data. This requires more technical expertise.</li> <li>Data consistency: Managing data consistency between the source and destination system is more complex as well. This can come in the form of schema evolution where a column changes data type, or missing data.</li> </ol> <h3 id="methods-of-incremental-load">Methods of Incremental Load</h3> <h4 id="timestamp-based-approach">Timestamp based approach</h4> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-03-20-full-vs-incremental-load/1-480.webp 480w,/assets/img/2025-03-20-full-vs-incremental-load/1-800.webp 800w,/assets/img/2025-03-20-full-vs-incremental-load/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-03-20-full-vs-incremental-load/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>In a timestamp based approach, the source table will need to have a timestamp column to reference, usually an <code class="language-plaintext highlighter-rouge">updated_at</code> column. Whenever a new record is added or an existing record (see Green) is updated in the source database, the <code class="language-plaintext highlighter-rouge">updated_at</code> column will reflect the latest timestamp. This allows us to keep track on the records that are updated after the last incremental load.</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">select</span> <span class="o">*</span>
<span class="k">from</span> <span class="n">source_table</span>
<span class="k">where</span> <span class="n">updated_at</span> <span class="o">&gt;</span> <span class="n">last_ingested_time</span>
</code></pre></div></div> <p>We can keep track of the last ingested time and identify new/updated records past the time.</p> <p>If you want to indicate if a row is an INSERT or and UPDATE, then you may need to modify the setup by changing the query or adding new columns such as <code class="language-plaintext highlighter-rouge">created_at</code>.</p> <p>In this approach, it’ll be difficult to identify records that is deleted (see Red) in the source system unless we do some comparison between the source and destination tables to identify primary keys that do not exist in the source. This is what we call a soft delete approach where we can mark the record in the target table with an <code class="language-plaintext highlighter-rouge">is_deleted</code> flag.</p> <h4 id="log-basedchange-data-capture-cdc-approach">Log based/Change data capture (CDC) approach</h4> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-03-20-full-vs-incremental-load/2-480.webp 480w,/assets/img/2025-03-20-full-vs-incremental-load/2-800.webp 800w,/assets/img/2025-03-20-full-vs-incremental-load/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-03-20-full-vs-incremental-load/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>This method is applicable to source databases such as Postgres which contains transaction logs. These transaction logs store all events that allows the databse to be recovered in the event of a crash. We can utilise this logs to capture the transactions (e.g. insert/update/delete) and propagate it to the destination system. The data changes are captured in real time by connecting a tool to capture the data changes. This method will not require any scanning of the source database. However the additional complexity may come from the additional tool and configurations to the database for this to work.</p> <h2 id="summary-table">Summary table</h2> <table> <thead> <tr> <th> </th> <th>Full Load</th> <th>Incremental Load</th> </tr> </thead> <tbody> <tr> <td>Data Volume</td> <td>Entire dataset overwritten each time</td> <td>Only changed data needs to be processed (insert, update, delete)</td> </tr> <tr> <td>Frequency</td> <td>Less frequent</td> <td>More frequent</td> </tr> <tr> <td>Resource Usage</td> <td>Higher</td> <td>Lower</td> </tr> <tr> <td>Latency/Speed</td> <td>Slower</td> <td>Faster</td> </tr> <tr> <td>Complexity</td> <td>Simpler</td> <td>Complex</td> </tr> <tr> <td>Data consistency</td> <td>Consistent since its an overwrite</td> <td>Requries reconciliation via some logic and risk being inconsistent</td> </tr> </tbody> </table>]]></content><author><name></name></author><category term="learning"/><category term="data_engineering"/><category term="ingestion"/><summary type="html"><![CDATA[Explaining pros and cons of Full Load vs Incremental Load]]></summary></entry><entry><title type="html">Benchmarking OLTP vs OLAP</title><link href="https://jkwd.github.io/blog/2025/oltp-vs-olap/" rel="alternate" type="text/html" title="Benchmarking OLTP vs OLAP"/><published>2025-02-21T00:00:00+00:00</published><updated>2025-02-21T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2025/oltp-vs-olap</id><content type="html" xml:base="https://jkwd.github.io/blog/2025/oltp-vs-olap/"><![CDATA[<h1 id="setup">Setup</h1> <ol> <li>git clone the <a href="https://github.com/jkwd/oltp_vs_olap">repo</a></li> <li>Install <a href="https://www.docker.com/get-started/">Docker</a></li> <li>Check if docker compose comes installed with Docker by running <code class="language-plaintext highlighter-rouge">docker compose version</code></li> <li>Install <a href="https://docs.docker.com/compose/install/">docker compose</a></li> <li>Run the docker componse</li> </ol> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone https://github.com/jkwd/oltp_vs_olap.git
cd oltp_vs_olap
docker compose version
docker compose up
</code></pre></div></div> <h1 id="data-source">Data Source</h1> <p>We are using the <a href="https://www.tpc.org/tpch/">TPC-H</a> data which is a decision support benchmark. It consists of a suite of business-oriented ad hoc queries and concurrent data modifications.</p> <h1 id="experiment">Experiment</h1> <p>We are going to benchmark the performance of an Online Transaction Processing (OLTP) database vs an Online analytical processing (OLAP) database on business-oriented query performance as well as transactional performance:</p> <ol> <li>business-oriented ad hoc query by <a href="https://docs.starrocks.io/docs/benchmarking/TPC-H_Benchmarking/#5-query-sql-and-create-table-statements">TPC-H</a></li> <li>INSERT N records</li> </ol> <p>The OLTP database we are using for the experiment is a Postgres database. The OLAP database we are using is DuckDB.</p> <h1 id="hypothesis">Hypothesis</h1> <p>The hypothesis is that the OLTP database will perform better for transactional operations such as INSERT/UPDATE/DELETE while the OLAP database will perform better for the business-oriented ad hoc query.</p> <h1 id="row-vs-column-oriented-storage">Row vs Column oriented Storage</h1> <h2 id="row-oriented-storage">Row oriented storage</h2> <p>In a row-oriented storage, each row in a table is stored sequentially on the disk.</p> <table> <thead> <tr> <th>id</th> <th>Name</th> <th>Country</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>Alice</td> <td>USA</td> </tr> <tr> <td>2</td> <td>Bob</td> <td>Germany</td> </tr> <tr> <td>3</td> <td>Charlie</td> <td>Australia</td> </tr> <tr> <td>4</td> <td>David</td> <td>Japan</td> </tr> </tbody> </table> <p>Given the example table above, a row oriented storage will be stored as:</p> <p><code class="language-plaintext highlighter-rouge">1 Alice USA | 2 Bob Germany | 3 Charlie Australia | 4 David Japan</code></p> <p>Each <code class="language-plaintext highlighter-rouge">|</code> represents the separation of a block and each row in the table is stored within the block.</p> <p>This makes the row oriented storage good for transactional use cases, which mainly focuses on INSERT/READ/UPDATE/DELETE of a single record, where if you need to update Bob’s Country from Germany to Italy, you can look for the specific block about Bob and update the value. This can be achieved by creating an index of the address of each block which then allows us to directly access the block that is needed.</p> <p>However, analytics queries will be poor as the column we need will be spread across the blocks. E.g. If we want to know the number of people in each country, we technically only need the <code class="language-plaintext highlighter-rouge">Country</code> column to count. This results in a full table scan just to get the results we want.</p> <h2 id="column-oriented-storage">Column oriented storage</h2> <p>In a column-oriented storage, each row in a table is stored sequentially on the disk.</p> <table> <thead> <tr> <th>id</th> <th>Name</th> <th>Country</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>Alice</td> <td>USA</td> </tr> <tr> <td>2</td> <td>Bob</td> <td>Germany</td> </tr> <tr> <td>3</td> <td>Charlie</td> <td>Australia</td> </tr> <tr> <td>4</td> <td>David</td> <td>Japan</td> </tr> </tbody> </table> <p>Given the example table above, a column oriented storage will be stored as:</p> <p><code class="language-plaintext highlighter-rouge">1 2 3 4 | Alice Bob Charlie David | USA Germany Australia Japan</code></p> <p>This makes an column oriented storage good for analytical queries. Going back to the previous example on wanting to know the number of people in each country, we just need to read 1 block of data which is the <code class="language-plaintext highlighter-rouge">Country</code> block and do our counting from there. Much lesser data is scanned and returned for the query.</p> <p>On the other hand, column oriented storage is poor for transactional processing which usually does an operation on 1 row. For example, if you wanted to add a row of data, each value from the new row has to be added to the correct block of the existing database. This requires accessing all the blocks. Column oriented storage will prefer doing operations in bulk (e.g. bulk insert/update).</p> <h1 id="result">Result</h1> <h2 id="query-performance">Query performance</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-21-oltp-vs-olap/1-480.webp 480w,/assets/img/2025-02-21-oltp-vs-olap/1-800.webp 800w,/assets/img/2025-02-21-oltp-vs-olap/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-21-oltp-vs-olap/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>DuckDB executed all the queries in less than a second. Postgres on the other hand took at least 3 seconds for the query execution to complete. In fact 1 of the query took longer than 50 seconds!</p> <h2 id="insert-performance">INSERT performance</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-02-21-oltp-vs-olap/2-480.webp 480w,/assets/img/2025-02-21-oltp-vs-olap/2-800.webp 800w,/assets/img/2025-02-21-oltp-vs-olap/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-02-21-oltp-vs-olap/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Postgres is about 4X faster when inserting records as compared to DuckDB.</p>]]></content><author><name></name></author><category term="project"/><category term="data_engineering"/><summary type="html"><![CDATA[Simple experiment on OLTP and OLAP databases using TPC-H dataset]]></summary></entry><entry><title type="html">Databricks DE Associate Notes</title><link href="https://jkwd.github.io/blog/2025/databricks-data-engineer-associate/" rel="alternate" type="text/html" title="Databricks DE Associate Notes"/><published>2025-01-10T00:00:00+00:00</published><updated>2025-01-10T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2025/databricks-data-engineer-associate</id><content type="html" xml:base="https://jkwd.github.io/blog/2025/databricks-data-engineer-associate/"><![CDATA[<h1 id="auto-generate-the-column-when-create-table">Auto generate the column when create table</h1> <ul> <li>GENERATED ALWAYS AS (CAST(orderTime as DATE))</li> </ul> <h1 id="auto-loader-streaming-vs-copy-into">Auto Loader (Streaming) vs Copy Into</h1> <p><code class="language-plaintext highlighter-rouge">Identified via cloudFiles in streaming</code></p> <ul> <li>Auto loader supports both directory listing and file notification but COPY INTO only supports directory listing. <ul> <li>Directory listing - List Directory and maintain the state in RocksDB, supports incremental file listing</li> <li>File notification - Uses a trigger+queue to store the file notification which can be later used to retrieve the file, unlike Directory listing File notification can scale up to millions of files per day.</li> </ul> </li> <li>Schema location is used to store schema inferred by AUTO LOADER <ul> <li>To allow AUTO LOADER to run faster next time</li> </ul> </li> <li>Use Auto Loader when <ul> <li>having large number of files</li> <li>schema evolve frequently</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2023-06-01-databricks-data-engineer-associate/1-480.webp 480w,/assets/img/2023-06-01-databricks-data-engineer-associate/1-800.webp 800w,/assets/img/2023-06-01-databricks-data-engineer-associate/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2023-06-01-databricks-data-engineer-associate/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li>COPY INTO keeps track of files that were successfully loaded into the table, the next time when the COPY INTO runs it skips them.</li> </ul> <h1 id="control-and-data-plane">Control and Data Plane</h1> <ul> <li>Control <ul> <li>Stored in Databricks Cloud Account</li> <li>Notebook commands and many other workspace configurations are stored in the control plane and encrypted at rest</li> </ul> </li> <li>Data <ul> <li>Stored in Customer Cloud Account</li> <li>For most Databricks computation, the compute resources are in your AWS account in what is called the <em>Classic data plane</em></li> </ul> </li> <li>Both <ul> <li>Interactive Notebook</li> </ul> </li> </ul> <h1 id="time-travel">Time Travel</h1> <h2 id="by-timestamp">By Timestamp</h2> <p><code class="language-plaintext highlighter-rouge">select * from table TIMESTAMP AS OF "2022-01-01"</code></p> <h2 id="by-version-number">By Version Number</h2> <p><code class="language-plaintext highlighter-rouge">select * from table VERSION AS OF 2</code></p> <p><code class="language-plaintext highlighter-rouge">select * from table@2</code></p> <p><code class="language-plaintext highlighter-rouge">select * from delta.'/path/to/table@2</code></p> <h2 id="restore">Restore</h2> <p><code class="language-plaintext highlighter-rouge">RESTORE table TO VERSION as of 2</code></p> <h1 id="temporary-view">Temporary View</h1> <ul> <li>Session scoped temp view <ul> <li>only available with a spark session, so another notebook in the same cluster can not access it</li> <li>if a notebook is detached and reattached local temporary view is lost</li> </ul> </li> <li>Global temp view <ul> <li>available to all the notebooks in the cluster</li> <li>can still be accessed when notebook is detached and attached</li> <li>if a cluster restarts global temporary view is lost</li> </ul> </li> </ul> <h1 id="udf">UDF</h1> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">FUNCTION</span> <span class="n">fn</span><span class="p">(...)</span>
<span class="k">RETURNS</span> <span class="nb">DOUBLE</span>
<span class="k">RETURN</span> <span class="o">&lt;</span><span class="n">expression</span><span class="o">&gt;</span>
</code></pre></div></div> <h1 id="permission">Permission</h1> <p><code class="language-plaintext highlighter-rouge">GOT</code>: GRANT <action> ON TABLE &lt;table&gt; TO &lt;user/group email&gt;</action></p> <p>To give all permission, use <code class="language-plaintext highlighter-rouge">ALL PRIVILEGES</code></p> <blockquote> <p>💡 Insert, Update, Delete are combined to <code class="language-plaintext highlighter-rouge">Modify</code></p> </blockquote> <h2 id="usage-privilege">Usage Privilege</h2> <p>To perform an action on a schema object in the Hive metastore, a user must have the <code class="language-plaintext highlighter-rouge">USAGE</code> privilege on that schema in addition to the privilege to perform that action. Any one of the following satisfies the <code class="language-plaintext highlighter-rouge">USAGE</code> requirement:</p> <ul> <li>Be a workspace admin</li> <li>Have the <code class="language-plaintext highlighter-rouge">USAGE</code> privilege on the schema or be in a group that has the <code class="language-plaintext highlighter-rouge">USAGE</code> privilege on the schema</li> <li>Have the <code class="language-plaintext highlighter-rouge">USAGE</code> privilege on the <code class="language-plaintext highlighter-rouge">CATALOG</code> or be in a group that has the <code class="language-plaintext highlighter-rouge">USAGE</code> privilege</li> <li>Be the owner of the schema or be in a group that owns the schema</li> </ul> <p>Even the owner of an object inside a schema must have the <code class="language-plaintext highlighter-rouge">USAGE</code> privilege in order to use it.</p> <h2 id="ownership">Ownership</h2> <ul> <li>Ownership determines whether or not you can grant privileges on derived objects to other users, since Steve is not the owner of the underlying sales table, he can not grant access to the table or data in the table indirectly</li> <li>A user who creates the object becomes its owner, does not matter who is the owner of the parent object</li> </ul> <h1 id="query-external-files">Query external files</h1> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">format</span><span class="p">.</span><span class="nv">`/Location`</span>
</code></pre></div></div> <p>format - CSV, JSON, PARQUET, TEXT</p> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="k">table_name</span> <span class="p">(</span><span class="n">col_name1</span> <span class="n">col_typ1</span><span class="p">,..)</span>
<span class="k">USING</span> <span class="n">data_source</span>
<span class="k">OPTIONS</span> <span class="p">(</span><span class="k">key</span><span class="o">=</span><span class="err">’</span><span class="n">value</span><span class="err">’</span><span class="p">,</span> <span class="n">key2</span><span class="o">=</span><span class="n">vla2</span><span class="p">)</span>
<span class="k">LOCATION</span> <span class="o">=</span> <span class="err">“</span><span class="o">/</span><span class="k">location</span><span class="err">“</span>
</code></pre></div></div> <p>^data_source = CSV, etc</p> <h1 id="drop-database-and-all-its-tables">Drop database and all its tables</h1> <p><code class="language-plaintext highlighter-rouge">DROP DATABASE customers CASCADE</code></p> <h1 id="create-jdbc-table">Create JDBC table</h1> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">users_jdbc</span>
<span class="k">USING</span> <span class="n">org</span><span class="p">.</span><span class="n">apache</span><span class="p">.</span><span class="n">spark</span><span class="p">.</span><span class="k">sql</span><span class="p">.</span><span class="n">jdbc</span>
<span class="k">OPTIONS</span> <span class="p">(</span>
    <span class="n">url</span> <span class="o">=</span> <span class="nv">"jdbc:sqlite:/sqmple_db"</span><span class="p">,</span>
    <span class="n">dbtable</span> <span class="o">=</span> <span class="nv">"users"</span>
<span class="p">)</span>
</code></pre></div></div> <h1 id="copy-table">Copy table</h1> <h2 id="shallow-clone">Shallow Clone</h2> <ul> <li>Shallow clones just copy the Delta transaction logs, meaning that the data doesn’t move so it can be very quick</li> </ul> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">TABLE</span> <span class="p">{</span><span class="n">new_table_name</span><span class="p">}</span>
<span class="n">SHALLOW</span> <span class="n">CLONE</span> <span class="p">{</span><span class="n">source_table_name</span><span class="p">}</span><span class="o">|</span><span class="p">[</span><span class="k">LOCATION</span> <span class="n">path</span><span class="p">]</span>
</code></pre></div></div> <h2 id="deep-clone">Deep Clone</h2> <ul> <li>It copies all of the data and transaction logs this can take a long time based on the size of the table</li> </ul> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">OR</span> <span class="k">REPLACE</span> <span class="k">TABLE</span> <span class="p">{</span><span class="n">new_table_name</span><span class="p">}</span>
<span class="n">DEEP</span> <span class="n">CLONE</span> <span class="p">{</span><span class="n">source_table_name</span><span class="p">}</span><span class="o">|</span><span class="p">[</span><span class="k">LOCATION</span> <span class="n">path</span><span class="p">]</span>
</code></pre></div></div> <h1 id="managedexternal-table">Managed/External table</h1> <h2 id="managed">Managed</h2> <p>A drop command will drop everything from metastore and storage.</p> <h2 id="external">External</h2> <p>A drop command will only drop data but not metadata and logs</p> <h1 id="structured-streaming">Structured Streaming</h1> <h2 id="limitations">Limitations</h2> <ul> <li>Multiple streaming aggregations (i.e. a chain of aggregations on a streaming DF) are not yet supported on streaming Datasets.</li> <li>Limit and take the first N rows are not supported on streaming Datasets.</li> <li>Distinct operations on streaming Datasets are not supported.</li> <li>Deduplication operation is not supported after aggregation on a streaming Datasets.</li> <li><code class="language-plaintext highlighter-rouge">Sorting operations are supported on streaming Datasets only after an aggregation and in Complete Output Mode.</code></li> </ul> <p><code class="language-plaintext highlighter-rouge">Note: Sorting without aggregation function is not supported.</code></p> <h2 id="properties-of-structured-streaming">Properties of structured streaming</h2> <ul> <li>Structured Streaming uses <code class="language-plaintext highlighter-rouge">checkpointing</code> and <code class="language-plaintext highlighter-rouge">write-ahead logs</code> to record the offset range of data being processed during each trigger interval.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Once
</span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span>
  <span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">events_log</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">groupBy</span><span class="p">(</span><span class="sh">"</span><span class="s">customerId</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">count</span><span class="p">()</span>
  <span class="p">.</span><span class="n">writeStream</span>
  <span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">outputMode</span><span class="p">(</span><span class="sh">"</span><span class="s">complete</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">checkpointLocation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">/tmp/delta/eventsByCustomer/_checkpoints/</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">trigger</span><span class="p">(</span><span class="n">once</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">target_table</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># every 15mins
</span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span>
  <span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">events_log</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">groupBy</span><span class="p">(</span><span class="sh">"</span><span class="s">customerId</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">count</span><span class="p">()</span>
  <span class="p">.</span><span class="n">writeStream</span>
  <span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">outputMode</span><span class="p">(</span><span class="sh">"</span><span class="s">complete</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">checkpointLocation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">/tmp/delta/eventsByCustomer/_checkpoints/</span><span class="sh">"</span><span class="p">)</span>
	<span class="p">.</span><span class="nf">trigger</span><span class="p">(</span><span class="n">processingTime</span> <span class="o">=</span> <span class="sh">"</span><span class="s">15 Minutes</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">target_table</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Available now
</span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span>
  <span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">events_log</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">groupBy</span><span class="p">(</span><span class="sh">"</span><span class="s">customerId</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">count</span><span class="p">()</span>
  <span class="p">.</span><span class="n">writeStream</span>
  <span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">"</span><span class="s">delta</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">outputMode</span><span class="p">(</span><span class="sh">"</span><span class="s">complete</span><span class="sh">"</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">option</span><span class="p">(</span><span class="sh">"</span><span class="s">checkpointLocation</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">/tmp/delta/eventsByCustomer/_checkpoints/</span><span class="sh">"</span><span class="p">)</span>
	<span class="p">.</span><span class="nf">trigger</span><span class="p">(</span><span class="n">availableNow</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
  <span class="p">.</span><span class="nf">table</span><span class="p">(</span><span class="sh">"</span><span class="s">target_table</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <h2 id="output-modes">Output modes</h2> <ul> <li>Append</li> <li>Update</li> <li>Complete</li> </ul> <h2 id="active-streams">Active streams</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">spark</span><span class="p">.</span><span class="n">streams</span><span class="p">.</span><span class="n">active</span><span class="p">:</span>
	<span class="n">s</span><span class="p">.</span><span class="nf">stop</span><span class="p">()</span>
</code></pre></div></div> <h1 id="delta-live-tables">Delta Live Tables</h1> <div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">create</span> <span class="k">or</span> <span class="k">replace</span> <span class="n">live</span> <span class="k">table</span> <span class="n">orders_valid</span>
<span class="p">(</span><span class="k">constraint</span> <span class="n">valid_timestamp</span> <span class="n">expect</span> <span class="p">(</span><span class="nb">timestamp</span> <span class="o">&gt;</span> <span class="nv">"2020-01-01"</span><span class="p">)</span> <span class="k">on</span> <span class="n">violation</span> <span class="k">drop</span> <span class="k">row</span><span class="p">)</span>
<span class="k">select</span> <span class="o">*</span> <span class="k">from</span> <span class="n">live</span><span class="p">.</span><span class="n">orders_vw</span>
</code></pre></div></div> <ul> <li>DLT pipeline supports two modes Development and Production, you can switch between the two based on the stage of your development and deployment lifecycle.</li> </ul> <h2 id="development">Development</h2> <ul> <li>Reuses a cluster to avoid the overhead of restarts</li> <li>Disables pipeline retries so you can immediately detect and fix errors</li> </ul> <h2 id="production">Production</h2> <ul> <li>Restarts the cluster for specific recoverable errors, including memory leaks and stale credentials</li> <li>Retries execution in the event of specific errors, for example, a failure to start a cluster</li> </ul> <h2 id="dlt-expectations">DLT Expectations</h2> <ul> <li>CONSTRAINT valid_timestamp EXPECT (timestamp &gt; ‘2020-01-01’) <ul> <li>Retain</li> <li>flag invalid in log</li> <li>pipeline continues</li> </ul> </li> <li>CONSTRAINT valid_timestamp EXPECT (timestamp &gt; ‘2020-01-01’) ON VIOLATION DROP ROW <ul> <li>Drop</li> <li>flag invalid in log</li> <li>pipeline continues</li> </ul> </li> <li>CONSTRAINT valid_timestamp EXPECT (timestamp &gt; ‘2020-01-01’) ON VIOLATION FAIL <ul> <li>job fail</li> </ul> </li> </ul> <p>Linking Notebook with DLT</p> <ul> <li>Single job can be used to set up both notebook and DLT pipeline, use two different tasks with linear dependency</li> </ul> <p>format - CSV, JSON, PARQUET, TEXT</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2023-06-01-databricks-data-engineer-associate/2-480.webp 480w,/assets/img/2023-06-01-databricks-data-engineer-associate/2-800.webp 800w,/assets/img/2023-06-01-databricks-data-engineer-associate/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2023-06-01-databricks-data-engineer-associate/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="alerts">Alerts</h1> <ul> <li>Alerts support custom template supports using variables to customize the default message</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2023-06-01-databricks-data-engineer-associate/3-480.webp 480w,/assets/img/2023-06-01-databricks-data-engineer-associate/3-800.webp 800w,/assets/img/2023-06-01-databricks-data-engineer-associate/3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2023-06-01-databricks-data-engineer-associate/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li>Alerts support webhook</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2023-06-01-databricks-data-engineer-associate/4-480.webp 480w,/assets/img/2023-06-01-databricks-data-engineer-associate/4-800.webp 800w,/assets/img/2023-06-01-databricks-data-engineer-associate/4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2023-06-01-databricks-data-engineer-associate/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="unity-catalog">Unity catalog</h1> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2023-06-01-databricks-data-engineer-associate/5-480.webp 480w,/assets/img/2023-06-01-databricks-data-engineer-associate/5-800.webp 800w,/assets/img/2023-06-01-databricks-data-engineer-associate/5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2023-06-01-databricks-data-engineer-associate/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="running-notebook">Running notebook</h1> <p><code class="language-plaintext highlighter-rouge">dbutils.notebook.run(" full notebook path ")</code></p> <p><code class="language-plaintext highlighter-rouge">run(path: String, timeout_seconds: int, arguments: Map): String</code></p>]]></content><author><name></name></author><category term="learning"/><category term="data_engineering"/><category term="databricks"/><summary type="html"><![CDATA[Notes for Databricks DE Associate Certification]]></summary></entry><entry><title type="html">Airflow Tutorial</title><link href="https://jkwd.github.io/blog/2025/airflow-notes/" rel="alternate" type="text/html" title="Airflow Tutorial"/><published>2025-01-10T00:00:00+00:00</published><updated>2025-01-10T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2025/airflow-notes</id><content type="html" xml:base="https://jkwd.github.io/blog/2025/airflow-notes/"><![CDATA[<h1 id="airflow-cli">Airflow CLI</h1> <ul> <li><code class="language-plaintext highlighter-rouge">airflow -h</code></li> </ul> <h2 id="dags">DAGs</h2> <ul> <li><code class="language-plaintext highlighter-rouge">airflow list_dags</code> <ul> <li>List all dags</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">airflow dag_state</code> <ul> <li>Get status of dag run</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">airflow test</code> <ul> <li>test task instance without checking dependencies or recording state in db</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">airflow dags trigger &lt;EXAMPLE_DAG&gt;</code> <ul> <li>Trigger the dag <EXAMPLE_DAG> with the current date as execution date</EXAMPLE_DAG></li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">airflow dags trigger &lt;EXAMPLE_DAG&gt; -e 2021-01-01</code> <ul> <li>Trigger the dag <EXAMPLE_DAG> with a date in the past as execution date (This won’t trigger the tasks of that dag unless you set the option catchup=True in the DAG definition)</EXAMPLE_DAG></li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">airflow dags list-runs -d &lt;EXAMPLE_DAG&gt;</code> <ul> <li>Display the history of <EXAMPLE_DAG> dag runs</EXAMPLE_DAG></li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">airflow dags backfill -s 2024-01-01 -e 2024-01-05 —reset-dagruns &lt;EXAMPLE_DAG&gt;</code> <ul> <li>Backfill from start date to end date</li> <li>—reset-dagruns will allow the airflow to run a dag even though it was ran before <ul> <li>Useful for backfilling jobs where you have made mistake previously</li> </ul> </li> </ul> </li> </ul> <h2 id="tasks">Tasks</h2> <ul> <li><code class="language-plaintext highlighter-rouge">airflow task_state</code> <ul> <li>Get status of task instance</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">airflow tasks list &lt;EXAMPLE_DAG&gt;</code> <ul> <li>List the tasks contained into the <EXAMPLE_DAG> dag</EXAMPLE_DAG></li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">airflow tasks test &lt;EXAMPLE_DAG&gt; &lt;EXAMPLE_TASK_IN_DAG&gt; 2021-01-01</code> <ul> <li>Allow to test a task (print_the_context) from a given dag without taking care of dependencies and past runs. Useful for debugging.</li> </ul> </li> </ul> <h1 id="operators">Operators</h1> <h2 id="sensors">Sensors</h2> <h3 id="httpsensor">HTTPSensor</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Full endpoint: https://gist.github.com/marclamberti/f45f872dea4dfd3eaa015a4a1af4b39b
</span><span class="n">is_forex_rates_available</span> <span class="o">=</span> <span class="nc">HttpSensor</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="sh">"</span><span class="s">is_forex_rates_available</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">http_conn_id</span><span class="o">=</span><span class="sh">"</span><span class="s">forex_api</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">endpoint</span><span class="o">=</span><span class="sh">"</span><span class="s">marclamberti/f45f872dea4dfd3eaa015a4a1af4b39b</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">response_check</span><span class="o">=</span><span class="k">lambda</span> <span class="n">response</span><span class="p">:</span> <span class="sh">"</span><span class="s">rates</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">response</span><span class="p">.</span><span class="n">text</span><span class="p">,</span>
    <span class="n">poke_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
    <span class="n">timeout</span><span class="o">=</span><span class="mi">20</span>
<span class="p">)</span>
</code></pre></div></div> <p>In AirflowUI <code class="language-plaintext highlighter-rouge">Admin → Connection</code></p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-airflow-notes/1-480.webp 480w,/assets/img/2025-01-10-airflow-notes/1-800.webp 800w,/assets/img/2025-01-10-airflow-notes/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-airflow-notes/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="filesensor">FileSensor</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">if_forex_currencies_file_avaiable</span> <span class="o">=</span> <span class="nc">FileSensor</span><span class="p">(</span>
      <span class="n">task_id</span><span class="o">=</span><span class="sh">"</span><span class="s">if_forex_currencies_file_avaiable</span><span class="sh">"</span><span class="p">,</span>
      <span class="n">fs_conn_id</span><span class="o">=</span><span class="sh">"</span><span class="s">forex_path</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># Base path from forex_path id
</span>      <span class="n">filepath</span><span class="o">=</span><span class="sh">"</span><span class="s">forex_currencies.csv</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># Name of file
</span>      <span class="n">poke_interval</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
      <span class="n">timeout</span><span class="o">=</span><span class="mi">20</span>
  <span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-airflow-notes/2-480.webp 480w,/assets/img/2025-01-10-airflow-notes/2-800.webp 800w,/assets/img/2025-01-10-airflow-notes/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-airflow-notes/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="python-operator">Python Operator</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">downloading_rates</span> <span class="o">=</span> <span class="nc">PythonOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="sh">"</span><span class="s">downloading_rates</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">python_callable</span><span class="o">=</span><span class="n">download_rates</span>
<span class="p">)</span>
</code></pre></div></div> <ul> <li>the python_callable <code class="language-plaintext highlighter-rouge">download_rates</code> is a python function to be called</li> </ul> <h2 id="bash-operator">Bash Operator</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">load_forex_rates_to_hdfs</span> <span class="o">=</span> <span class="nc">BashOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="sh">"</span><span class="s">load_forex_rates_to_hdfs</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">bash_command</span><span class="o">=</span><span class="sh">"""</span><span class="s">
        hdfs dfs -mkdir -p /forex &amp;&amp; </span><span class="se">\
</span><span class="s">        hdfs dfs -put -f $AIRFLOW_HOME/dags/files/forex_rates.json /forex
    </span><span class="sh">"""</span>
<span class="p">)</span>
</code></pre></div></div> <ul> <li>Need to create a connection on the airflow UI</li> </ul> <h2 id="spark-operator">Spark Operator</h2> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">forex_processing</span> <span class="o">=</span> <span class="nc">SparkSubmitOperator</span><span class="p">(</span>
    <span class="n">task_id</span><span class="o">=</span><span class="sh">"</span><span class="s">forex_processing</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">application</span><span class="o">=</span><span class="sh">"</span><span class="s">/opt/airflow/dags/scripts/forex_processing.py</span><span class="sh">"</span><span class="p">,</span> <span class="c1"># Path of the spark script
</span>    <span class="n">conn_id</span><span class="o">=</span><span class="sh">"</span><span class="s">spark_conn</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="bp">False</span>
<span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-airflow-notes/3-480.webp 480w,/assets/img/2025-01-10-airflow-notes/3-800.webp 800w,/assets/img/2025-01-10-airflow-notes/3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-airflow-notes/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="parameters">Parameters</h1> <h2 id="important-params">Important Params</h2> <ul> <li>start_date - Date which tasks of DAG can be scheduled and triggered <ul> <li><code class="language-plaintext highlighter-rouge">datetime.datetime(2019,1,1)</code> <ul> <li>Do not use dynamic values like <code class="language-plaintext highlighter-rouge">datetime.now()</code></li> </ul> </li> <li>Set at DAG level through default_args</li> </ul> </li> <li>schedule_interval - Interval of time from min(start_date) at which DAG should be triggered <ul> <li>Cron (0 * * * *) - preferred</li> <li><code class="language-plaintext highlighter-rouge">datetime.timedelta(days=1))</code></li> </ul> </li> </ul> <blockquote> <p>💡 A DAG starts being scheduled from <code class="language-plaintext highlighter-rouge">start_date</code> and triggered after every <code class="language-plaintext highlighter-rouge">schedule_interval</code></p> </blockquote> <ul> <li>execution_date - beginning of the processed period <ul> <li>Given <code class="language-plaintext highlighter-rouge">start_date=2019-09-19T02:00:00 UTC</code> and <code class="language-plaintext highlighter-rouge">schedule_interval=every hour</code> <ul> <li>execution_date=2019-09-19T<code class="language-plaintext highlighter-rouge">01</code>:00:00 UTC</li> </ul> </li> </ul> </li> <li>end_date - Date the DAG will stop running</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-airflow-notes/4-480.webp 480w,/assets/img/2025-01-10-airflow-notes/4-800.webp 800w,/assets/img/2025-01-10-airflow-notes/4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-airflow-notes/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="backfill--catchup">Backfill &amp; Catchup</h1> <h2 id="backfill">Backfill</h2> <p><code class="language-plaintext highlighter-rouge">airflow backfill -s 2019-01-20 -e 2019-01-25 --rerun_failed_tasks -B &lt;DAG_ID&gt;</code></p> <ul> <li>-s: start date</li> <li>-e: end date</li> <li>-B: backfill from latest to earliest</li> </ul> <h1 id="timezones">Timezones</h1> <ul> <li>Naive - datetime object without the tzinfo</li> <li>Aware - datetime object with tzinfo</li> </ul> <blockquote> <p>💡 Always use Aware. Note: datetime obj without timezone IS NOT UTC</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">local_tz</span> <span class="o">=</span> <span class="n">pendulum</span><span class="p">.</span><span class="nf">timezone</span><span class="p">(</span><span class="sh">"</span><span class="s">Europe/Paris</span><span class="sh">"</span><span class="p">)</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">:</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2019</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">29</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tzinfo</span><span class="o">=</span><span class="n">local_tz</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">owner</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Airflow</span><span class="sh">'</span>
<span class="p">}</span>
</code></pre></div></div> <h1 id="makes-dag-task-dependent">Makes DAG Task Dependent</h1> <ul> <li><code class="language-plaintext highlighter-rouge">depends_on_past</code> - Set task to depend on previous run - Only run if its the same task in the previous run is successful (Left to right)</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-airflow-notes/5-480.webp 480w,/assets/img/2025-01-10-airflow-notes/5-800.webp 800w,/assets/img/2025-01-10-airflow-notes/5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-airflow-notes/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li><code class="language-plaintext highlighter-rouge">wait_for_downstream</code> - Set on task level - Task X will wait for tasks <code class="language-plaintext highlighter-rouge">immediately</code> downstream of previous instance of task X (In prev dag run) to finish successfully before running</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-airflow-notes/6-480.webp 480w,/assets/img/2025-01-10-airflow-notes/6-800.webp 800w,/assets/img/2025-01-10-airflow-notes/6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-airflow-notes/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Here <code class="language-plaintext highlighter-rouge">DAG Run 3 sleep task</code> waits for <code class="language-plaintext highlighter-rouge">DAGRun 2 templated tast</code> (downstream task of the previous DAG) to complete successfully before running.</p> <h1 id="slaalerts">SLA/Alerts</h1> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">on_success_dag</span><span class="p">(</span><span class="nb">dict</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">on_success_dag</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_failure_dag</span><span class="p">(</span><span class="nb">dict</span><span class="p">):</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">on_failure_dag</span><span class="sh">"</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="nb">dict</span><span class="p">)</span>

<span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">start_date</span><span class="sh">'</span><span class="p">:</span> <span class="nf">datetime</span><span class="p">(</span><span class="mi">2024</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">22</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">owner</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">Airflow</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">retries</span><span class="sh">'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">retry_delay</span><span class="sh">'</span><span class="p">:</span> <span class="nf">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="mi">60</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">emails</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="sh">'</span><span class="s">owner@company.com</span><span class="sh">'</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">email_on_failure</span><span class="sh">'</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">email_on_retry</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span>
<span class="p">}</span>

<span class="k">with</span> <span class="nc">DAG</span><span class="p">(</span><span class="n">dag_id</span><span class="o">=</span><span class="sh">'</span><span class="s">alert_dag</span><span class="sh">'</span><span class="p">,</span>
         <span class="n">schedule_interval</span><span class="o">=</span><span class="sh">"</span><span class="s">44 6 * * *</span><span class="sh">"</span><span class="p">,</span>
         <span class="n">default_args</span><span class="o">=</span><span class="n">default_args</span><span class="p">,</span>
         <span class="n">catchup</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
         <span class="n">dagrun_timeout</span><span class="o">=</span><span class="nf">timedelta</span><span class="p">(</span><span class="n">seconds</span><span class="o">=</span><span class="mi">25</span><span class="p">),</span>
         <span class="n">on_success_callback</span><span class="o">=</span><span class="n">on_success_dag</span><span class="p">,</span>
         <span class="n">on_failure_callback</span><span class="o">=</span><span class="n">on_failure_dag</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">dag</span><span class="p">:</span>
</code></pre></div></div> <h2 id="sla">SLA</h2> <ul> <li><code class="language-plaintext highlighter-rouge">dagrun_timeout=timedelta(seconds=25)</code> can be used to stop the dagrun in failure</li> </ul> <h2 id="successfailure-callbacks">Success/Failure Callbacks</h2> <ul> <li>Allows you to do something when the dag fail/succeed</li> </ul> <h2 id="email">Email</h2> <ul> <li>Email on failure: To email if dagrun fails</li> <li>Email on retry: To email when a retry happens</li> </ul> <h1 id="unit-testing-dag">Unit Testing DAG</h1> <ul> <li>Dag validation test <ul> <li>Check if there are cycles</li> <li>Check default args</li> </ul> </li> <li>Dag/pipeline definition test <ul> <li>Check upstream/downstream tasks</li> <li>Check number of tasks</li> </ul> </li> <li>Unit test <ul> <li>Check logic</li> </ul> </li> <li>Integration test <ul> <li>Need dev/test/acceptance/prod env</li> </ul> </li> <li>End to end pipeline test <ul> <li>Check output is correct</li> <li>Check full logic</li> <li>Need dev/test/acceptance/prod env</li> </ul> </li> </ul> <h2 id="environment">Environment</h2> <ul> <li>Dev <ul> <li>Small mock data</li> <li>DAG validation + pipeline test</li> <li>Unit test</li> </ul> </li> <li>Test <ul> <li>Larger real data</li> <li>Integration test</li> </ul> </li> <li>Acceptance <ul> <li>Copy of prod</li> <li>End to end test</li> </ul> </li> <li>Prod <ul> <li>Prod</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="learning"/><category term="data_engineering"/><category term="orchestrator"/><summary type="html"><![CDATA[Notes on Airflow]]></summary></entry><entry><title type="html">Docker Tutorial</title><link href="https://jkwd.github.io/blog/2025/docker-notes/" rel="alternate" type="text/html" title="Docker Tutorial"/><published>2025-01-10T00:00:00+00:00</published><updated>2025-01-10T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2025/docker-notes</id><content type="html" xml:base="https://jkwd.github.io/blog/2025/docker-notes/"><![CDATA[<h1 id="tutorial-source">Tutorial Source</h1> <p><a href="https://www.youtube.com/watch?v=3c-iBn73dDE">TechWorld with Nane - Docker Tutorial for Beginners [FULL COURSE in 3 Hours]</a></p> <h1 id="common-commands">Common commands</h1> <p>Below are some of the common commands that you’ll use for Docker.</p> <h2 id="get-artefactsimages">Get artefacts/images</h2> <p>To find the images, you may go to <a href="https://hub.docker.com/_/postgres">Docker Hub</a> and search for the relevant images.</p> <p>To get the latest image may run the following command</p> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull postgres
</code></pre></div></div> <p>If you wish to get a specific version you may add a tag at the back, e.g. version 10.10</p> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker pull postgres:10.10
</code></pre></div></div> <h2 id="run-images">Run images</h2> <h3 id="attached-mode">Attached mode</h3> <p>To run the image simply run the following command</p> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run postgres:10.10
</code></pre></div></div> <p>If the image was not pulled earlier, Docker will pull and run the image afterwards. However this will run in attached mode and the terminal needs to maintain in this state.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/1-480.webp 480w,/assets/img/2025-01-10-docker-notes/1-800.webp 800w,/assets/img/2025-01-10-docker-notes/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <blockquote> <p>💡 By using Ctrl + C, this will stop the container</p> </blockquote> <p><br/></p> <h3 id="running-in-detach-mode">Running in Detach mode</h3> <p>To run the container in detach mode, run the following command</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker run -d postgress:10.10
</code></pre></div></div> <h3 id="port-forwardingbinding">Port forwarding/binding</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/2-480.webp 480w,/assets/img/2025-01-10-docker-notes/2-800.webp 800w,/assets/img/2025-01-10-docker-notes/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Sometimes if we require to run more than 1 application in the same host machine, they might conflict with using the same port. To solve this, we will need to change the port of the local machine to point to as shown in the example.</p> <blockquote> <p>💡 Container ports can be the same as they are the image ports. But as long as the host machine ports are not used twice then it is ok.</p> </blockquote> <p>To port forward, we may use the following command</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># docker run -p&lt;HOST PORT&gt;:&lt;IMAGE PORT&gt; -d postgres:10.10
docker run -p3000:5432 -d postgres:10.10
</code></pre></div></div> <p>where <code class="language-plaintext highlighter-rouge">3000</code> is the port in the host binding to container’s <code class="language-plaintext highlighter-rouge">5432</code></p> <p>Example of running 2 images via different host ports:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/3-480.webp 480w,/assets/img/2025-01-10-docker-notes/3-800.webp 800w,/assets/img/2025-01-10-docker-notes/3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="naming-containers-upon-run">Naming containers upon run</h2> <p>Docker Names are randomly assigned. If you wish to name the container for easier reference you may run the following command</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#docker run -p&lt;HOST PORT&gt;:&lt;IMAGE PORT&gt; --name &lt;NAME&gt; -d &lt;IMAGE&gt;:&lt;TAG&gt;
docker run -p3000:5432 --name pg_abc -d postgres:10.10
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/4-480.webp 480w,/assets/img/2025-01-10-docker-notes/4-800.webp 800w,/assets/img/2025-01-10-docker-notes/4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="running-with-environmental-variables">Running with environmental variables</h2> <p>Some images may use environmental variables in order to run. E.g. <a href="https://hub.docker.com/_/mongo">Mongo DB</a>.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># use -e with the key-value pair for the environment variables
docker run -p 27017:27017 -d --name some-mongo \
    -e MONGO_INITDB_ROOT_USERNAME=admin \
    -e MONGO_INITDB_ROOT_PASSWORD=password \
    mongo
</code></pre></div></div> <h2 id="mounting-volume-for-persistence-of-data-in-containers">Mounting volume for persistence of data in containers</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/5-480.webp 480w,/assets/img/2025-01-10-docker-notes/5-800.webp 800w,/assets/img/2025-01-10-docker-notes/5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="types-of-volumes">Types of Volumes</h3> <ol> <li>Host Volumes</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/6-480.webp 480w,/assets/img/2025-01-10-docker-notes/6-800.webp 800w,/assets/img/2025-01-10-docker-notes/6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li>Anonymous Volumes</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/7-480.webp 480w,/assets/img/2025-01-10-docker-notes/7-800.webp 800w,/assets/img/2025-01-10-docker-notes/7-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li>Named Volumes</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/8-480.webp 480w,/assets/img/2025-01-10-docker-notes/8-800.webp 800w,/assets/img/2025-01-10-docker-notes/8-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="stop-containers">Stop containers</h2> <p>You may stop the running containers using the following command</p> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># docker stop &lt;CONTAINER ID&gt;</span>
docker stop fe8836ce13cb
</code></pre></div></div> <h2 id="start-containers">Start containers</h2> <p>Likewise, you may start a container using the following command</p> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># docker start &lt;CONTAINER ID&gt;</span>
docker start fe8836ce13cb
</code></pre></div></div> <p>The container will still maintain the same attribute at time of creation in the <code class="language-plaintext highlighter-rouge">docker run</code> step.</p> <h2 id="list-containers">List containers</h2> <h3 id="list-running-containers">List running containers</h3> <p>You may view running containers using the following command</p> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker ps
</code></pre></div></div> <p>This will only show you currently running containers.</p> <h3 id="list-running-and-stopped-containers">List Running and stopped containers</h3> <p>If you have stopped containers previously, use the following command to see all running and stopped containers.</p> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker ps -a
</code></pre></div></div> <h1 id="docker-network">Docker Network</h1> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/9-480.webp 480w,/assets/img/2025-01-10-docker-notes/9-800.webp 800w,/assets/img/2025-01-10-docker-notes/9-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>We package images into a network so that containers are able to find and talk to each other.</p> <h2 id="list-docker-networks">List docker networks</h2> <p>To see the available docker networks we use the following command</p> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker network ls
</code></pre></div></div> <h2 id="create-docker-network">Create docker network</h2> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># docker network create &lt;NETORK NAME&gt;</span>
docker network create mongo-network
</code></pre></div></div> <h2 id="running-containers-in-the-same-network">Running containers in the same network</h2> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># use --network &lt;NETWORK NAME&gt; to run the container in the network</span>
docker run -d \
-p 27017:27017 \
--network mongo-network \
--name mongodb \
-e MONGO_INITDB_ROOT_USERNAME=admin \
-e MONGO_INITDB_ROOT_PASSWORD=password \
mongo

docker run -d \
-p 8081:8081 \
-e ME_CONFIG_MONGODB_ADMINUSERNAME=admin \
-e ME_CONFIG_MONGODB_ADMINPASSWORD=password \
-e ME_CONFIG_MONGODB_SERVER=mongodb \
--network mongo-network \
--name mongo-express \
mongo-express
</code></pre></div></div> <h1 id="docker-compose">Docker Compose</h1> <p>Instead of always running multiple run commands, we can combine them into a yaml file.</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="s1">'</span><span class="s">1'</span>
<span class="na">services</span><span class="pi">:</span>
  <span class="na">my-app</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">${docker-registry}/my-app:1.0</span> <span class="c1"># &lt;IMAGE : From Private Repo&gt;</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">3000:3000</span>

<span class="na">	mongodb</span><span class="pi">:</span> <span class="c1"># &lt;CONTAINER NAME&gt;</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">mongo</span> <span class="c1"># &lt;IMAGE : Default is from Public Docker Hub&gt;</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">27017:27017</span> <span class="c1"># &lt;HOST:CONTAINER&gt;</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">MONGO_INITDB_ROOT_USERNAME=admin</span>
      <span class="pi">-</span> <span class="s">MONGO_INITDB_ROOT_PASSWORD=password</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="c1">#&lt;REFERENCE NAME:CONTAINER DIRECTORY&gt;</span>
      <span class="pi">-</span> <span class="s">mongo-data:/data/db</span>

  <span class="na">mongo-express</span><span class="pi">:</span> <span class="c1"># &lt;CONTAINER NAME&gt;</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">mongo-express</span> <span class="c1"># &lt;IMAGE : Default is from Public Docker Hub&gt;</span>
    <span class="na">restart</span><span class="pi">:</span> <span class="s">always</span> <span class="c1"># fixes MongoNetworkError when mongodb is not ready when mongo-express starts</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">8080:8081</span> <span class="c1"># &lt;HOST:CONTAINER&gt;</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">ME_CONFIG_MONGODB_ADMINUSERNAME=admin</span>
      <span class="pi">-</span> <span class="s">ME_CONFIG_MONGODB_ADMINPASSWORD=password</span>
      <span class="pi">-</span> <span class="s">ME_CONFIG_MONGODB_SERVER=mongodb</span>

<span class="na">volumes</span><span class="pi">:</span>
  <span class="na">mongo-data</span><span class="pi">:</span> <span class="c1"># &lt;volume from mongodb&gt;</span>
    <span class="na">driver</span><span class="pi">:</span> <span class="s">local</span> <span class="c1"># &lt;additional info for docker to create a physical storage locally&gt;</span>
</code></pre></div></div> <blockquote> <p>💡 Do not need to specify network as containers in the same yaml file are in the same network.</p> </blockquote> <h2 id="start-containers-using-docker-compose">Start containers using docker-compose</h2> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># docker-compose -f &lt;YAML_FILE&gt;.yaml up</span>
docker-compose -d -f mongo.yaml up
</code></pre></div></div> <h2 id="stop-containers-using-docker-compose">Stop containers using docker-compose</h2> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># docker-compose -f &lt;YAML_FILE&gt;.yaml down</span>
docker-compose -f mongo.yaml down
</code></pre></div></div> <blockquote> <p>💡 This also removes the network</p> </blockquote> <h1 id="dockerfile">Dockerfile</h1> <p>After developing and testing a app, it can be packaged into its own docker container for deployment. This image is built via a Dockerfile. This step is usually done at Jenkins side before pushing into the Docker Repository.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-docker-notes/10-480.webp 480w,/assets/img/2025-01-10-docker-notes/10-800.webp 800w,/assets/img/2025-01-10-docker-notes/10-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-docker-notes/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#FROM &lt;IMAGE&gt;</span>
<span class="k">FROM</span><span class="s"> node:13-alpine</span>

<span class="c"># OPTIONAL BUT NOT RECOMMENDED</span>
<span class="c"># It is better to set env externally at docker-compose instaed of rebuild image</span>
<span class="c"># ENV MONGO_DB_USERNAME=admin \</span>
<span class="c">#		MONGO_DB_PWD=password</span>

<span class="c"># RUN allows to execute any Linux command</span>
<span class="c"># Directory will be on container and not on host</span>
<span class="c"># Can have multiple RUN commands</span>
<span class="k">RUN </span><span class="nb">mkdir</span> <span class="nt">-p</span> /home/app

<span class="c"># &lt;HOST SOURCE&gt; &lt;CONTAINER DEST&gt;</span>
<span class="k">COPY</span><span class="s"> . /home/app</span>

<span class="c">#CMD is an entrypoint command. Only 1 CMD</span>
<span class="k">CMD</span><span class="s"> ["node", "/home/app/server.js"]</span>

</code></pre></div></div> <h2 id="building-an-image-from-dockerfile">Building an image from Dockerfile</h2> <div class="language-docker highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#docker build -t &lt;IMAGE NAME&gt;:&lt;TAG&gt; &lt;LOCATION OF DOCKERFILE&gt;</span>
docker build -t my-app:1.0 .
</code></pre></div></div>]]></content><author><name></name></author><category term="learning"/><category term="data_engineering"/><category term="infra"/><category term="docker"/><summary type="html"><![CDATA[Notes on Docker]]></summary></entry><entry><title type="html">Terraform Tutorial</title><link href="https://jkwd.github.io/blog/2025/terraform-notes/" rel="alternate" type="text/html" title="Terraform Tutorial"/><published>2025-01-10T00:00:00+00:00</published><updated>2025-01-10T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2025/terraform-notes</id><content type="html" xml:base="https://jkwd.github.io/blog/2025/terraform-notes/"><![CDATA[<h1 id="setup">Setup</h1> <h2 id="windows">Windows</h2> <ol> <li>https://www.terraform.io/downloads</li> <li>Set Env Path <ol> <li>System Variables → Path</li> </ol> </li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/1-480.webp 480w,/assets/img/2025-01-10-terraform-notes/1-800.webp 800w,/assets/img/2025-01-10-terraform-notes/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li>Add path to environment</li> </ol> <h2 id="mac-via-homebrew">Mac via Homebrew</h2> <ol> <li>https://brew.sh/</li> <li>Copy command</li> <li>Paste command in Terminal to install Homebrew</li> <li>Install terraform</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>terraform
</code></pre></div></div> <h2 id="test-terraform-using-cmdterminal">Test Terraform using cmd/terminal</h2> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform <span class="nt">-v</span>
</code></pre></div></div> <h2 id="mac-via-binary-download">Mac via binary download</h2> <ol> <li>https://www.terraform.io/downloads</li> <li>Unzip file</li> <li>echo $PATH to see list of locations</li> <li>move terraform binary to one of the locations <ol> <li>Generally use <code class="language-plaintext highlighter-rouge">usr/local/bin</code></li> </ol> </li> </ol> <h1 id="tutorial">Tutorial</h1> <p>Terraform is declarative in nature and therefore we are configuring what we want to see in the cloud instead of how much we want to add/remove from the cloud.</p> <h2 id="cloud-provider">Cloud Provider</h2> <ol> <li>Select Cloud to configure (AWS)</li> <li>https://registry.terraform.io/providers/hashicorp/aws/latest/docs</li> </ol> <h2 id="configure-the-provider-and-region">Configure the Provider and Region</h2> <ol> <li>Create a <code class="language-plaintext highlighter-rouge">.tf</code> file. E.g. <code class="language-plaintext highlighter-rouge">main.tf</code></li> </ol> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Configure the AWS Provider</span>
<span class="k">provider</span> <span class="s2">"aws"</span> <span class="p">{</span>
  <span class="nx">region</span> <span class="o">=</span> <span class="s2">"ap-southeast-1"</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="setup-authentication">Setup Authentication</h2> <h3 id="1-get-access-and-secret-key-from-cloud-provider">1. Get Access and Secret Key from Cloud Provider</h3> <ol> <li>AWS</li> <li>Profile Name</li> <li>Security Credentials</li> <li>Access Key Tab</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/2-480.webp 480w,/assets/img/2025-01-10-terraform-notes/2-800.webp 800w,/assets/img/2025-01-10-terraform-notes/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ol> <li>Create New Access Key</li> <li>Show Access Key <ol> <li>This will provide the value for <code class="language-plaintext highlighter-rouge">access_key</code> and <code class="language-plaintext highlighter-rouge">secret_key</code></li> </ol> </li> <li>Download Key File as <code class="language-plaintext highlighter-rouge">secret_key</code> will not be able to be found anymore after you close the tab</li> </ol> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Configure the AWS Provider</span>
<span class="k">provider</span> <span class="s2">"aws"</span> <span class="p">{</span>
  <span class="nx">region</span> <span class="o">=</span> <span class="s2">"ap-southeast-1"</span>
  <span class="nx">access_key</span> <span class="o">=</span> <span class="s2">"my-access-key"</span>
  <span class="nx">secret_key</span> <span class="o">=</span> <span class="s2">"my-secret-key"</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="create-resources">Create Resources</h2> <p>E.g. Resources includes EC2, etc.</p> <h3 id="syntax-for-creating-resources">Syntax for creating resources</h3> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"&lt;provider&gt;_&lt;resource_type&gt;"</span> <span class="s2">"&lt;name&gt;"</span> <span class="p">{</span>
  <span class="c1"># config options in key value pairs</span>
  <span class="nx">key</span> <span class="o">=</span> <span class="s2">"value"</span>
  <span class="nx">key2</span> <span class="o">=</span> <span class="s2">"value2"</span>
<span class="p">}</span>
</code></pre></div></div> <h3 id="creating-ec2-instance">Creating EC2 Instance</h3> <p>https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/instance</p> <ol> <li>Obtain AMI from AWS to be used in the code</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/3-480.webp 480w,/assets/img/2025-01-10-terraform-notes/3-800.webp 800w,/assets/img/2025-01-10-terraform-notes/3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Configure the AWS Provider</span>
<span class="k">provider</span> <span class="s2">"aws"</span> <span class="p">{</span>
  <span class="nx">region</span> <span class="o">=</span> <span class="s2">"ap-southeast-1"</span>
  <span class="nx">access_key</span> <span class="o">=</span> <span class="s2">"my-access-key"</span>
  <span class="nx">secret_key</span> <span class="o">=</span> <span class="s2">"my-secret-key"</span>
<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_instance"</span> <span class="s2">"my-first-server"</span> <span class="p">{</span>
  <span class="nx">ami</span>           <span class="o">=</span> <span class="s2">"ami-055d15d9cfddf7bd3"</span>
  <span class="nx">instance_type</span> <span class="o">=</span> <span class="s2">"t2.micro"</span>

  <span class="nx">tags</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nx">Name</span> <span class="o">=</span> <span class="s2">"ubuntu"</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="terraform-init">Terraform Init</h2> <p>Looks at the config in <code class="language-plaintext highlighter-rouge">.tf</code> files and look for all the providers defined and will download all the plugins required.</p> <ol> <li>Navigate terminal to where the <code class="language-plaintext highlighter-rouge">.tf</code> file is</li> </ol> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform init
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/4-480.webp 480w,/assets/img/2025-01-10-terraform-notes/4-800.webp 800w,/assets/img/2025-01-10-terraform-notes/4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="terraform-plan">Terraform Plan</h2> <p>Does a dry run of the code and show you all the changes that is going to be applied Delete/Create/Modify any instances.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform plan
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/5-480.webp 480w,/assets/img/2025-01-10-terraform-notes/5-800.webp 800w,/assets/img/2025-01-10-terraform-notes/5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="terraform-apply">Terraform Apply</h2> <p>Run the code to production.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform apply
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/6-480.webp 480w,/assets/img/2025-01-10-terraform-notes/6-800.webp 800w,/assets/img/2025-01-10-terraform-notes/6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/7-480.webp 480w,/assets/img/2025-01-10-terraform-notes/7-800.webp 800w,/assets/img/2025-01-10-terraform-notes/7-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="terraform-destroy">Terraform Destroy</h2> <p>Delete the whole architecture. Usually will not do this and will instead make changes within the file and use <code class="language-plaintext highlighter-rouge">terraform apply</code> to add/remove instances from the architecture.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform destroy
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/8-480.webp 480w,/assets/img/2025-01-10-terraform-notes/8-800.webp 800w,/assets/img/2025-01-10-terraform-notes/8-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/9-480.webp 480w,/assets/img/2025-01-10-terraform-notes/9-800.webp 800w,/assets/img/2025-01-10-terraform-notes/9-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="destroying-specific-resource">Destroying specific resource</h3> <ol> <li>See the resources that are tracked by terraform <code class="language-plaintext highlighter-rouge">terraform state list</code></li> <li>Remove the states that you DO NOT want to destroy<code class="language-plaintext highlighter-rouge">terraform state rm &lt;resource1&gt; &lt;resource2&gt; &lt;resource3&gt; ...</code></li> <li><code class="language-plaintext highlighter-rouge">terraform destroy</code> to destroy the rest of the available states</li> </ol> <h2 id="referencing-resources">Referencing Resources</h2> <p>You can reference other resources by pointing to the <code class="language-plaintext highlighter-rouge">&lt;provider&gt;_&lt;resource_type&gt;.&lt;name&gt;.id</code></p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">resource</span> <span class="s2">"aws_vpc"</span> <span class="s2">"first-vpc"</span> <span class="p">{</span>
  <span class="nx">cidr_block</span>       <span class="o">=</span> <span class="s2">"10.0.0.0/16"</span>

  <span class="nx">tags</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nx">Name</span> <span class="o">=</span> <span class="s2">"production"</span>
  <span class="p">}</span>

<span class="p">}</span>

<span class="k">resource</span> <span class="s2">"aws_subnet"</span> <span class="s2">"subnet-1"</span> <span class="p">{</span>
 <span class="c1"># this is taking from the resource name above. Every resource has id property to access</span>
  <span class="nx">vpc_id</span>     <span class="o">=</span> <span class="nx">aws_vpc</span><span class="p">.</span><span class="nx">first-vpc</span><span class="p">.</span><span class="nx">id</span>
  <span class="nx">cidr_block</span> <span class="o">=</span> <span class="s2">"10.0.1.0/24"</span>

  <span class="nx">tags</span> <span class="o">=</span> <span class="p">{</span>
    <span class="nx">Name</span> <span class="o">=</span> <span class="s2">"prod-subnet"</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/10-480.webp 480w,/assets/img/2025-01-10-terraform-notes/10-800.webp 800w,/assets/img/2025-01-10-terraform-notes/10-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="terraform-files">Terraform Files</h2> <p><code class="language-plaintext highlighter-rouge">terraform init</code> creates a <code class="language-plaintext highlighter-rouge">.terraform</code> folder in the directory that contains the configs for the resources.</p> <p><code class="language-plaintext highlighter-rouge">terraform.tfstate</code> contains the state of terraform so that when we make any modifications/etc., it will be able to check the current status and compare against the code.</p> <h2 id="terraform-state-list">Terraform State List</h2> <p>This shows all the resources that was created along with the resource name</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform state list
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/11-480.webp 480w,/assets/img/2025-01-10-terraform-notes/11-800.webp 800w,/assets/img/2025-01-10-terraform-notes/11-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="terraform-state-show">Terraform State Show</h2> <p>This shows the detailed output regarding the state which would normally be stored in the console.</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># terraform state show &lt;resource&gt;.&lt;resource_name&gt;</span>
terraform state show aws_eip.one
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/12-480.webp 480w,/assets/img/2025-01-10-terraform-notes/12-800.webp 800w,/assets/img/2025-01-10-terraform-notes/12-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="terraform-output">Terraform Output</h2> <p>This will print out the details and prints out in the console after <code class="language-plaintext highlighter-rouge">terraform refresh</code>. You can only have 1 value per output.</p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># output "&lt;output_key_name&gt;" {</span>
<span class="c1">#   value = &lt;resource_type&gt;.&lt;resource_name&gt;.&lt;property&gt;</span>
<span class="c1"># }</span>

<span class="k">output</span> <span class="s2">"server_public_ip"</span> <span class="p">{</span>
  <span class="nx">value</span> <span class="o">=</span> <span class="nx">aws_eip</span><span class="p">.</span><span class="nx">one</span><span class="p">.</span><span class="nx">public_ip</span>
<span class="p">}</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/13-480.webp 480w,/assets/img/2025-01-10-terraform-notes/13-800.webp 800w,/assets/img/2025-01-10-terraform-notes/13-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <blockquote> <p>💡 Be careful when you want to add new outputs and see the outputs. Not a good idea to use terraform apply as that might make changes on production side.</p> </blockquote> <h2 id="target-resources">Target Resources</h2> <p>This will only <code class="language-plaintext highlighter-rouge">apply/destroy</code> changes to a specific resource instead of potentially changing everything in production (e.g. route table, subnet)</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># terraform destroy -target &lt;resource&gt;.&lt;resource_name&gt;</span>
<span class="c"># terraform apply -target &lt;resource&gt;.&lt;resource_name&gt;</span>

terraform apply <span class="nt">-target</span> aws_eip.one
</code></pre></div></div> <h2 id="variables">Variables</h2> <p>This will allow terraform file to reference a variable. Generally passed at runtime.</p> <div class="language-terraform highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">variable</span> <span class="s2">"variable_name"</span> <span class="p">{</span>
  <span class="nx">description</span> <span class="o">=</span> <span class="s2">""</span>
  <span class="nx">default</span> <span class="o">=</span> <span class="s2">"abcd"</span>
  <span class="nx">type</span> <span class="o">=</span> <span class="nx">String</span>
<span class="p">}</span>

<span class="c1"># To access the variable</span>
<span class="kd">var</span><span class="err">.</span><span class="nx">variable_name</span>
</code></pre></div></div> <h3 id="method-1-input-value-at-terraform-apply-user-prompt">Method 1: Input value at Terraform Apply user prompt</h3> <p>If a value is not defined in the variable, at <code class="language-plaintext highlighter-rouge">terraform apply/destroy</code>, user will be prompted to submit a value</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-10-terraform-notes/14-480.webp 480w,/assets/img/2025-01-10-terraform-notes/14-800.webp 800w,/assets/img/2025-01-10-terraform-notes/14-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-10-terraform-notes/14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="method-2-input-value-as-part-of-command">Method 2: Input value as part of command</h3> <p>Alternatively, we can use <code class="language-plaintext highlighter-rouge">-var</code> to specify the value of the variable during <code class="language-plaintext highlighter-rouge">terraform apply</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform apply <span class="nt">-var</span> <span class="s2">"variable_name=abcd"</span>
</code></pre></div></div> <h3 id="method-3-input-value-at-tfvars-file">Method 3: Input value at .tfvars file</h3> <p>We can create a <code class="language-plaintext highlighter-rouge">.tfvars</code> file to store the values of the variables. E.g. <code class="language-plaintext highlighter-rouge">example.tfvars</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>variable_name <span class="o">=</span> <span class="s2">"abcd"</span>
</code></pre></div></div> <p>Run the <code class="language-plaintext highlighter-rouge">main.tf</code> file referencing the file via <code class="language-plaintext highlighter-rouge">-var-file</code></p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>terraform apply <span class="nt">-var-file</span> example.tfvars
</code></pre></div></div>]]></content><author><name></name></author><category term="learning"/><category term="data_engineering"/><category term="infra"/><category term="terraform"/><summary type="html"><![CDATA[Notes on Terraform]]></summary></entry><entry><title type="html">Github Actions Tutorial</title><link href="https://jkwd.github.io/blog/2025/github-actions/" rel="alternate" type="text/html" title="Github Actions Tutorial"/><published>2025-01-10T00:00:00+00:00</published><updated>2025-01-10T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2025/github-actions</id><content type="html" xml:base="https://jkwd.github.io/blog/2025/github-actions/"><![CDATA[<h1 id="example">Example</h1> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">Deploy Workflow</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_dispatch</span><span class="pi">:</span>
  <span class="na">pull_request</span><span class="pi">:</span>
    <span class="na">types</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">opened</span>
      <span class="pi">-</span> <span class="s">edited</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
      <span class="pi">-</span> <span class="s1">'</span><span class="s">dev-*'</span> <span class="c1"># * allows anything other then '/' E.g. dev-new dev-another</span>
      <span class="pi">-</span> <span class="s1">'</span><span class="s">feat/**'</span> <span class="c1">#** allows for more '/'. E.g. feat/new #feat/new/button</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
      <span class="pi">-</span> <span class="s1">'</span><span class="s">dev-*'</span> <span class="c1"># * allows anything other then '/' E.g. dev-new dev-another</span>
      <span class="pi">-</span> <span class="s1">'</span><span class="s">feat/**'</span> <span class="c1">#** allows for more '/'. E.g. feat/new #feat/new/button</span>
    <span class="na">paths-ignore</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s1">'</span><span class="s">.github/workflows/*'</span>
<span class="na">env</span><span class="pi">:</span>
  <span class="na">WORKFLOW_ENV_1</span><span class="pi">:</span> <span class="s">gha-demo</span> <span class="c1"># Workflow level</span>
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">lint</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache dependencies</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">cache</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">node_modules</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">deps-node-modules-$</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
        <span class="na">if</span><span class="pi">:</span> <span class="s">steps.cache.outputs.cache-hit != 'true'</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Lint code</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm run lint</span>
  <span class="na">test</span><span class="pi">:</span>
    <span class="c1"># Job level environment</span>
    <span class="na">env</span><span class="pi">:</span>
      <span class="na">JOB_ENV_1</span><span class="pi">:</span>
      <span class="na">JOB_ENV_1</span><span class="pi">:</span>
      <span class="na">JOB_ENV_1</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache dependencies</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">cache</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">node_modules</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">deps-node-modules-$</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
        <span class="na">if</span><span class="pi">:</span> <span class="s">steps.cache.outputs.cache-hit != 'true'</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Test code</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">run-tests</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm run test</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Upload test report</span>
        <span class="na">if</span><span class="pi">:</span> <span class="s">failure() &amp;&amp; steps.run-tests.outcome == 'failure'</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/upload-artifact@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">test-report</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">test.json</span>
  <span class="na">build</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">test</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">outputs</span><span class="pi">:</span>
      <span class="na">script-file</span><span class="pi">:</span> <span class="s">$</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache dependencies</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">cache</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">node_modules</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">deps-node-modules-$</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
        <span class="na">if</span><span class="pi">:</span> <span class="s">steps.cache.outputs.cache-hit != 'true'</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Build website</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm run build</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Publish JS filename</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">publish</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">find dist/assets/*.js -type f -execdir echo 'script={}' &gt;&gt; $GITHUB_OUTPUT ';'</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Upload artifacts</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/upload-artifact@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">dist-files</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">dist</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">build</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get build artifacts</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/download-artifact@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">dist-files</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output contents</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">ls</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output filename</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "$"</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Deploy</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "Deploying..."</span>
  <span class="na">report</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">lint</span><span class="pi">,</span> <span class="nv">deploy</span><span class="pi">]</span> <span class="c1"># To force the report job to run last</span>
    <span class="na">if</span><span class="pi">:</span> <span class="s">failure()</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output info</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">echo "something went wrong..."</span>
          <span class="s">echo "$"</span>
</code></pre></div></div> <blockquote> <p>💡 YML file needs to be stored in <code class="language-plaintext highlighter-rouge">.github/workflows</code> directory</p> </blockquote> <h1 id="workflow">Workflow</h1> <ul> <li>Requires the <code class="language-plaintext highlighter-rouge">name</code> of the workflow</li> <li>Requires the <code class="language-plaintext highlighter-rouge">on</code> to listen to events to trigger the workflow</li> </ul> <h2 id="event-listeners">Event Listeners</h2> <ul> <li><code class="language-plaintext highlighter-rouge">workflow_dispatch</code> <ul> <li>manual trigger</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">pull_request</code> <ul> <li>requires types - has some default types if not specified</li> <li>Allows for branches/path targetted</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">push</code> <ul> <li>Allows for branches/path targetted</li> </ul> </li> </ul> <blockquote> <p>💡 branches and paths have the compliment version (e.g. branch-ignore/path-ignore). Event Listeners operate on an OR condition within the branch/path and AND condition betwenn branch/path</p> </blockquote> <h1 id="jobs">Jobs</h1> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">jobs</span><span class="pi">:</span>
  <span class="na">build</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">test</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Build website</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm run build</span>
</code></pre></div></div> <ul> <li>Requres the <code class="language-plaintext highlighter-rouge">runs-on</code> to specify the type of machine the steps will run on</li> <li><code class="language-plaintext highlighter-rouge">needs</code> is used to specify the upstream job dependency (e.g. <code class="language-plaintext highlighter-rouge">build</code> job depends on <code class="language-plaintext highlighter-rouge">test</code>)</li> </ul> <h2 id="steps">Steps</h2> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">steps</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
    <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>

  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install NodeJS</span>
    <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/setup-node@v3</span>
    <span class="na">with</span><span class="pi">:</span>
      <span class="na">node-version</span><span class="pi">:</span> <span class="m">18</span>

  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
    <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">run</code> - anything eg bash commands etc</li> <li><code class="language-plaintext highlighter-rouge">uses</code>- uses existing github actions packages to help <ul> <li><code class="language-plaintext highlighter-rouge">with</code>- additional parameters to be used with the actions package</li> </ul> </li> </ul> <h1 id="skip-workflow">Skip Workflow</h1> <ul> <li><code class="language-plaintext highlighter-rouge">git commit -m "Add comment [skip ci]"</code> <ul> <li>To not make workflow run for this particular push</li> </ul> </li> </ul> <h1 id="job-artifacts--outputs">Job Artifacts &amp; Outputs</h1> <h2 id="artifacts">Artifacts</h2> <h3 id="upload-artifacts">Upload artifacts</h3> <ul> <li>Output from the workflow, e.g. log files or app binaries from build</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">steps</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
    <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
    <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Build website</span>
    <span class="na">run</span><span class="pi">:</span> <span class="s">npm run build</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Upload artifacts</span>
    <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/upload-artifact@v3</span>
    <span class="na">with</span><span class="pi">:</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">dist-files</span>
      <span class="na">path</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">dist</span>
        <span class="s">package.json</span>
</code></pre></div></div> <ul> <li>Artifacts shown in github actions workflow <ul> <li>Contains both dist and package.json as specified above</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/1-480.webp 480w,/assets/img/2025-01-13-github-actions/1-800.webp 800w,/assets/img/2025-01-13-github-actions/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="col-sm-6 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/2-480.webp 480w,/assets/img/2025-01-13-github-actions/2-800.webp 800w,/assets/img/2025-01-13-github-actions/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h3 id="downloading-artifacts">Downloading artifacts</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">steps</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get build artifacts</span>
    <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/download-artifact@v3</span>
    <span class="na">with</span><span class="pi">:</span>
      <span class="na">name</span><span class="pi">:</span> <span class="s">dist-files</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output contents</span>
    <span class="na">run</span><span class="pi">:</span> <span class="s">ls</span>
</code></pre></div></div> <ul> <li>Files are already unpacked</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/3-480.webp 480w,/assets/img/2025-01-13-github-actions/3-800.webp 800w,/assets/img/2025-01-13-github-actions/3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="job-outputs">Job Outputs</h2> <ul> <li>Different from artifacts <ul> <li>Typically used for reusing value in downstream jobs (e.g. name of file)</li> </ul> </li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">build</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">test</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">outputs</span><span class="pi">:</span>
      <span class="na">script-file</span><span class="pi">:</span> <span class="s">$</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Build website</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm run build</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Publish JS filename</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">publish</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">find dist/assets/*.js -type f -execdir echo 'script={}' &gt;&gt; $GITHUB_OUTPUT ';'</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Upload artifacts</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/upload-artifact@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">dist-files</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">dist</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">build</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get build artifacts</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/download-artifact@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">dist-files</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output contents</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">ls</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output filename</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "$"</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Deploy</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "Deploying..."</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/4-480.webp 480w,/assets/img/2025-01-13-github-actions/4-800.webp 800w,/assets/img/2025-01-13-github-actions/4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="col-sm-9 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/5-480.webp 480w,/assets/img/2025-01-13-github-actions/5-800.webp 800w,/assets/img/2025-01-13-github-actions/5-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h1 id="dependency-caching">Dependency Caching</h1> <ul> <li>Cache repeated steps to reduce time of workflow</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/6-480.webp 480w,/assets/img/2025-01-13-github-actions/6-800.webp 800w,/assets/img/2025-01-13-github-actions/6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>https://github.com/actions/cache/blob/main/examples.md#node—npm</p> <ul> <li>Looks for the file hash of the dependency installation details (In js is package-lock.json) <ul> <li>To be used in all the repeated palces with the same <code class="language-plaintext highlighter-rouge">key</code></li> </ul> </li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">test</span><span class="pi">:</span>
  <span class="c1"># Do something above</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache dependencies</span>
    <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v3</span>
    <span class="na">with</span><span class="pi">:</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s">~/.npm</span>
      <span class="na">key</span><span class="pi">:</span> <span class="s">deps-node-modules-$</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
    <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
  <span class="pi">-</span> <span class="s">...</span>
<span class="na">build</span><span class="pi">:</span>
  <span class="c1"># Do something above</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache dependencies</span>
    <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v3</span>
    <span class="na">with</span><span class="pi">:</span>
      <span class="na">path</span><span class="pi">:</span> <span class="s">~/.npm</span>
      <span class="na">key</span><span class="pi">:</span> <span class="s">deps-node-modules-$</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
    <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
  <span class="pi">-</span> <span class="s">...</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/7-480.webp 480w,/assets/img/2025-01-13-github-actions/7-800.webp 800w,/assets/img/2025-01-13-github-actions/7-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/8-480.webp 480w,/assets/img/2025-01-13-github-actions/8-800.webp 800w,/assets/img/2025-01-13-github-actions/8-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="environment-variables">Environment Variables</h1> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
      <span class="pi">-</span> <span class="s">dev</span>
<span class="na">env</span><span class="pi">:</span>
  <span class="na">MONGODB_DB_NAME</span><span class="pi">:</span> <span class="s">gha-demo</span> <span class="c1"># Workflow level ENV_VAR</span>
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">test</span><span class="pi">:</span>
    <span class="c1"># Job level ENV_VAR</span>
    <span class="na">env</span><span class="pi">:</span>
      <span class="na">MONGODB_CLUSTER_ADDRESS</span><span class="pi">:</span> <span class="s">cluster_1.mongodb.net</span>
      <span class="na">MONGODB_USERNAME</span><span class="pi">:</span> <span class="s">admin</span>
      <span class="na">MONGODB_PASSWORD</span><span class="pi">:</span> <span class="s">admin</span>
      <span class="na">PORT</span><span class="pi">:</span> <span class="m">8080</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="c1"># Do something above</span>
      <span class="c1"># Reference the job level env var PORT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run server</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm start &amp; npx wait-on http://127.0.0.1:$PORT</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="c1"># Previous Job ENV_VARs not accessible</span>
</code></pre></div></div> <h1 id="secrets">Secrets</h1> <h2 id="repository-secrets">Repository Secrets</h2> <ul> <li>To prevent pushing username/passwords into the <code class="language-plaintext highlighter-rouge">.github/workflows/</code> code <ul> <li>Create via Repository secrets</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/9-480.webp 480w,/assets/img/2025-01-13-github-actions/9-800.webp 800w,/assets/img/2025-01-13-github-actions/9-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
      <span class="pi">-</span> <span class="s">dev</span>
<span class="na">env</span><span class="pi">:</span>
  <span class="na">MONGODB_DB_NAME</span><span class="pi">:</span> <span class="s">gha-demo</span> <span class="c1"># Workflow level ENV_VAR</span>
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">test</span><span class="pi">:</span>
    <span class="c1"># Job level ENV_VAR</span>
    <span class="na">env</span><span class="pi">:</span>
      <span class="na">MONGODB_CLUSTER_ADDRESS</span><span class="pi">:</span> <span class="s">cluster_1.mongodb.net</span>
      <span class="na">MONGODB_USERNAME</span><span class="pi">:</span> <span class="s">$</span>
      <span class="na">MONGODB_PASSWORD</span><span class="pi">:</span> <span class="s">$</span>
      <span class="na">PORT</span><span class="pi">:</span> <span class="m">8080</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="c1"># Do something above</span>
      <span class="c1"># Reference the job level env var PORT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run server</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm start &amp; npx wait-on http://127.0.0.1:$PORT</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="c1"># Previous Job ENV_VARs not accessible</span>
</code></pre></div></div> <blockquote> <p>💡 When echo the environment variable with secrets, it’ll hide the info and print <code class="language-plaintext highlighter-rouge">***</code></p> </blockquote> <h2 id="environment-secrets">Environment Secrets</h2> <ul> <li>Allow you to have different secret values for different environment <ul> <li>Testing</li> <li>Production</li> </ul> </li> <li>Allows secrets to be used on certain branch/tag logic</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/10-480.webp 480w,/assets/img/2025-01-13-github-actions/10-800.webp 800w,/assets/img/2025-01-13-github-actions/10-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/11-480.webp 480w,/assets/img/2025-01-13-github-actions/11-800.webp 800w,/assets/img/2025-01-13-github-actions/11-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">Deployment</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
      <span class="pi">-</span> <span class="s">dev</span>
<span class="na">env</span><span class="pi">:</span>
  <span class="na">MONGODB_DB_NAME</span><span class="pi">:</span> <span class="s">gha-demo</span> <span class="c1"># Workflow level ENV_VAR</span>
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">test</span><span class="pi">:</span>
    <span class="na">environment</span><span class="pi">:</span> <span class="s">testing</span> <span class="c1"># To use the environment secrets named 'testing'</span>
    <span class="c1"># Job level ENV_VAR</span>
    <span class="na">env</span><span class="pi">:</span>
      <span class="na">MONGODB_CLUSTER_ADDRESS</span><span class="pi">:</span> <span class="s">cluster_1.mongodb.net</span>
      <span class="na">MONGODB_USERNAME</span><span class="pi">:</span> <span class="s">$</span>
      <span class="na">MONGODB_PASSWORD</span><span class="pi">:</span> <span class="s">$</span>
      <span class="na">PORT</span><span class="pi">:</span> <span class="m">8080</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="c1"># Do something above</span>
      <span class="c1"># Reference the job level env var PORT</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run server</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm start &amp; npx wait-on http://127.0.0.1:$PORT</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="c1"># Previous Job ENV_VARs not accessible</span>
</code></pre></div></div> <h1 id="execution-flow">Execution flow</h1> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/12-480.webp 480w,/assets/img/2025-01-13-github-actions/12-800.webp 800w,/assets/img/2025-01-13-github-actions/12-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="step-level-if-condition">Step level if condition</h2> <h3 id="failure-example">Failure example</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Test code</span>
  <span class="na">id</span><span class="pi">:</span> <span class="s">run-tests</span>
  <span class="na">run</span><span class="pi">:</span> <span class="s">npm run test</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Upload test report</span>
  <span class="na">if</span><span class="pi">:</span> <span class="s">failure() &amp;&amp; steps.run-tests.outcome == 'failure'</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/upload-artifact@v3</span>
  <span class="na">with</span><span class="pi">:</span>
    <span class="na">name</span><span class="pi">:</span> <span class="s">test-report</span>
    <span class="na">path</span><span class="pi">:</span> <span class="s">test.json</span>
</code></pre></div></div> <blockquote> <p>💡 <code class="language-plaintext highlighter-rouge">failure()</code> is required in order to run the Upload test report step</p> </blockquote> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/13-480.webp 480w,/assets/img/2025-01-13-github-actions/13-800.webp 800w,/assets/img/2025-01-13-github-actions/13-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="cache-example">Cache example</h3> <p>If node_modules exist then do not need to install dependencies</p> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache dependencies</span>
  <span class="na">id</span><span class="pi">:</span> <span class="s">cache</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v3</span>
  <span class="na">with</span><span class="pi">:</span>
    <span class="na">path</span><span class="pi">:</span> <span class="s">node_modules</span>
    <span class="na">key</span><span class="pi">:</span> <span class="s">deps-node-modules-$</span>
<span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
  <span class="na">if</span><span class="pi">:</span> <span class="s">steps.cache.outputs.cache-hit != 'true'</span>
  <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
</code></pre></div></div> <h2 id="job-level-if-condition">Job level if condition</h2> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">report</span><span class="pi">:</span>
  <span class="na">needs</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">lint</span><span class="pi">,</span> <span class="nv">deploy</span><span class="pi">]</span> <span class="c1"># To force the report job to run last</span>
  <span class="na">if</span><span class="pi">:</span> <span class="s">failure()</span>
  <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
  <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output info</span>
      <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">echo "something went wrong..."</span>
        <span class="s">echo "$"</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/14-480.webp 480w,/assets/img/2025-01-13-github-actions/14-800.webp 800w,/assets/img/2025-01-13-github-actions/14-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="matrix-strategy">Matrix strategy</h1> <ul> <li>Allows to run same job with multiple different configurations</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">Matrix Demo</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>

<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">lint</span><span class="pi">:</span>
    <span class="na">continue-on-erro</span><span class="pi">:</span> <span class="kc">true</span> <span class="c1"># To let the rest of the jobs run if 1 fails</span>
    <span class="na">strategy</span><span class="pi">:</span>
      <span class="na">matrix</span><span class="pi">:</span>
        <span class="c1"># Create 3 x 2 combinations</span>
        <span class="na">node-version</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">12</span><span class="pi">,</span> <span class="nv">14</span><span class="pi">,</span> <span class="nv">16</span><span class="pi">]</span>
        <span class="na">operating-system</span><span class="pi">:</span> <span class="pi">[</span><span class="nv">ubuntu-latest</span><span class="pi">,</span> <span class="nv">windows-latest</span><span class="pi">]</span>
        <span class="c1"># Exclude combination in the matrix</span>
        <span class="na">exclude</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">node-version</span><span class="pi">:</span> <span class="m">12</span>
            <span class="na">operating-system</span><span class="pi">:</span> <span class="s">windows-latest</span>
        <span class="c1"># Add single combination not part of matrix</span>
        <span class="na">include</span><span class="pi">:</span>
          <span class="pi">-</span> <span class="na">node-version</span><span class="pi">:</span> <span class="m">18</span>
            <span class="na">operating-system</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">$</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install NodeJS</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/setup-node@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">node-version</span><span class="pi">:</span> <span class="s">$</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache dependencies</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">cache</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">node_modules</span>
          <span class="na">key</span><span class="pi">:</span> <span class="s">deps-node-modules-$</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
        <span class="na">if</span><span class="pi">:</span> <span class="s">steps.cache.outputs.cache-hit != 'true'</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm ci</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Lint code</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm run lint</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/15-480.webp 480w,/assets/img/2025-01-13-github-actions/15-800.webp 800w,/assets/img/2025-01-13-github-actions/15-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/15.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="reusable-workflow">Reusable workflow</h1> <ul> <li>Create a workflow that can be referenced and used from another workflow <ul> <li>Allows inputs to make it dynamic</li> <li>Allows passing info back to the wofkflow calling it</li> </ul> </li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">Reusable Deploy</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">workflow_call</span><span class="pi">:</span> <span class="c1"># Allows this workflow to be called from other workflow</span>
    <span class="na">inputs</span><span class="pi">:</span>
      <span class="na">artifact-name</span><span class="pi">:</span>
        <span class="na">description</span><span class="pi">:</span> <span class="s">The name of the deployable artifact file</span>
        <span class="na">required</span><span class="pi">:</span> <span class="kc">false</span>
        <span class="na">default</span><span class="pi">:</span> <span class="s">dist</span>
        <span class="na">type</span><span class="pi">:</span> <span class="s">string</span>
    <span class="na">outputs</span><span class="pi">:</span>
      <span class="na">result</span><span class="pi">:</span>
        <span class="na">description</span><span class="pi">:</span> <span class="s">Result of the deployment operation</span>
        <span class="na">value</span><span class="pi">:</span> <span class="s">$</span>
    <span class="na">secrets</span><span class="pi">:</span>
      <span class="na">some-secret</span><span class="pi">:</span>
        <span class="na">required</span><span class="pi">:</span> <span class="kc">false</span>
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">outputs</span><span class="pi">:</span>
      <span class="na">outcome</span><span class="pi">:</span> <span class="s">$</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get Code Binaries</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/download-artifact@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">$</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">List files</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">ls</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output info</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "Deploying..."</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Set result output</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">set-result</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "step-result=success" &gt;&gt; $GITHUB_OUTPUT</span>
</code></pre></div></div> <blockquote> <p>💡 on needs to be workflow_call</p> </blockquote> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">Use Reusable</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">main</span>
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">lint</span><span class="pi">:</span> <span class="s">...</span>
  <span class="na">test</span><span class="pi">:</span> <span class="s">...</span>
  <span class="na">build</span><span class="pi">:</span> <span class="s">...</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">build</span>
    <span class="na">uses</span><span class="pi">:</span> <span class="s">./.github/workflows/reusable.yml</span> <span class="c1"># yml of the workflow to use</span>
    <span class="na">with</span><span class="pi">:</span>
      <span class="na">artifact-name</span><span class="pi">:</span> <span class="s">dist-files</span> <span class="c1"># To pass the variable over to reusable.yml</span>
    <span class="na">secrets</span><span class="pi">:</span>
      <span class="na">some-secret</span><span class="pi">:</span> <span class="s">$</span>
  <span class="na">print-deploy-result</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">deploy</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Print deploy output</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "$"</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/16-480.webp 480w,/assets/img/2025-01-13-github-actions/16-800.webp 800w,/assets/img/2025-01-13-github-actions/16-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/16.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h1 id="run-jobs-on-docker-containers">Run Jobs on docker containers</h1> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">jobs</span><span class="pi">:</span>
  <span class="na">test</span><span class="pi">:</span>
    <span class="na">environment</span><span class="pi">:</span> <span class="s">testing</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">container</span><span class="pi">:</span> <span class="c1"># DEFINE HERE. HOSTED ON ubuntu-latest</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">node:16</span>
      <span class="na">env</span><span class="pi">:</span> <span class="c1"># THIS IS ENV_VAR FOR IMAGE AND NOT STEPS</span>
        <span class="na">VAR_1</span><span class="pi">:</span> <span class="s">val_1</span>
    <span class="na">env</span><span class="pi">:</span>
      <span class="na">MONGODB_CONNECTION_PROTOCOL</span><span class="pi">:</span> <span class="s">mongodb+srv</span>
      <span class="na">MONGODB_CLUSTER_ADDRESS</span><span class="pi">:</span> <span class="s">cluster0.ntrwp.mongodb.net</span>
      <span class="na">MONGODB_USERNAME</span><span class="pi">:</span> <span class="s">$</span>
      <span class="na">MONGODB_PASSWORD</span><span class="pi">:</span> <span class="s">$</span>
      <span class="na">PORT</span><span class="pi">:</span> <span class="m">8080</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">...</span>
      <span class="pi">-</span> <span class="s">...</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/17-480.webp 480w,/assets/img/2025-01-13-github-actions/17-800.webp 800w,/assets/img/2025-01-13-github-actions/17-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/17.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="service-containers">Service Containers</h2> <ul> <li>To host a isolated testing db inside the github action job instead of connecting to the prod db</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/18-480.webp 480w,/assets/img/2025-01-13-github-actions/18-800.webp 800w,/assets/img/2025-01-13-github-actions/18-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/18.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="using-service-with-container">Using Service with Container</h3> <ul> <li>Create a mongodb service inside node:16 container with network name as mongodb-service</li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">jobs</span><span class="pi">:</span>
  <span class="na">test</span><span class="pi">:</span>
    <span class="na">environment</span><span class="pi">:</span> <span class="s">testing</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">container</span><span class="pi">:</span> <span class="c1"># DEFINE HERE. HOSTED ON ubuntu-latest</span>
      <span class="na">image</span><span class="pi">:</span> <span class="s">node:16</span>
      <span class="na">env</span><span class="pi">:</span> <span class="c1"># THIS IS ENV_VAR FOR IMAGE AND NOT STEPS</span>
        <span class="na">VAR_1</span><span class="pi">:</span> <span class="s">VAL_1</span>
    <span class="na">env</span><span class="pi">:</span>
      <span class="na">MONGODB_CONNECTION_PROTOCOL</span><span class="pi">:</span> <span class="s">mongodb</span>
      <span class="na">MONGODB_CLUSTER_ADDRESS</span><span class="pi">:</span> <span class="s">mongodb-service</span>
      <span class="na">MONGODB_USERNAME</span><span class="pi">:</span> <span class="s">root</span> <span class="c1"># Testing DB details</span>
      <span class="na">MONGODB_PASSWORD</span><span class="pi">:</span> <span class="s">example</span>
      <span class="na">PORT</span><span class="pi">:</span> <span class="m">8080</span>
    <span class="na">services</span><span class="pi">:</span> <span class="c1"># ALWAYS RUN INSIDE OF IMAGES</span>
      <span class="na">mongodb-service</span><span class="pi">:</span> <span class="c1"># Testing DB - will be deleted after job ends</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">mongo</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">MONGO_INITDB_ROOT_USERNAME</span><span class="pi">:</span> <span class="s">root</span>
          <span class="na">MONGO_INITDB_ROOT_PASSWORD</span><span class="pi">:</span> <span class="s">example</span>
      <span class="na">another-service</span><span class="pi">:</span> <span class="s">...</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">...</span>
</code></pre></div></div> <blockquote> <p>💡 If job runs in container, then github actions will handle the networking between the container and service for you. Hence in above example, <code class="language-plaintext highlighter-rouge">MONGODB_CLUSTER_ADDRESS</code> can be set to the name of the service <code class="language-plaintext highlighter-rouge">mongodb-service</code></p> </blockquote> <h3 id="using-service-without-container">Using Service without container</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">jobs</span><span class="pi">:</span>
  <span class="na">test</span><span class="pi">:</span>
    <span class="na">environment</span><span class="pi">:</span> <span class="s">testing</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">env</span><span class="pi">:</span>
      <span class="na">MONGODB_CONNECTION_PROTOCOL</span><span class="pi">:</span> <span class="s">mongodb</span>
      <span class="na">MONGODB_CLUSTER_ADDRESS</span><span class="pi">:</span> <span class="s">127.0.0.1:27017</span>
      <span class="na">MONGODB_USERNAME</span><span class="pi">:</span> <span class="s">root</span> <span class="c1"># Testing DB details</span>
      <span class="na">MONGODB_PASSWORD</span><span class="pi">:</span> <span class="s">example</span>
      <span class="na">PORT</span><span class="pi">:</span> <span class="m">8080</span>
    <span class="na">services</span><span class="pi">:</span> <span class="c1"># ALWAYS RUN INSIDE OF IMAGES</span>
      <span class="na">mongodb-service</span><span class="pi">:</span> <span class="c1"># Testing DB - will be deleted after job ends</span>
        <span class="na">image</span><span class="pi">:</span> <span class="s">mongo</span>
        <span class="na">ports</span><span class="pi">:</span> <span class="c1"># Need to open the mongodb port</span>
          <span class="pi">-</span> <span class="s">27017:27017</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">MONGO_INITDB_ROOT_USERNAME</span><span class="pi">:</span> <span class="s">root</span>
          <span class="na">MONGO_INITDB_ROOT_PASSWORD</span><span class="pi">:</span> <span class="s">example</span>
      <span class="na">another-service</span><span class="pi">:</span> <span class="s">...</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">...</span>
</code></pre></div></div> <blockquote> <p>💡 If no containers are used, then the service port will need to be opened and changing the <code class="language-plaintext highlighter-rouge">MONGODB_CLUSTER_ADDRESS</code></p> </blockquote> <h1 id="custom-actions">Custom Actions</h1> <ul> <li>3 kinds of custom actions</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/19-480.webp 480w,/assets/img/2025-01-13-github-actions/19-800.webp 800w,/assets/img/2025-01-13-github-actions/19-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/19.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="composite-actions">Composite Actions</h2> <p>Stored in</p> <ol> <li>New repository of actions</li> <li>Locally within <code class="language-plaintext highlighter-rouge">.github/&lt;folder_name&gt;/&lt;action_name&gt;/action.yml</code></li> </ol> <h3 id="example-custom-composite-action">Example (Custom Composite Action)</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Get</span><span class="nv"> </span><span class="s">&amp;</span><span class="nv"> </span><span class="s">Cache</span><span class="nv"> </span><span class="s">Dependencies"</span>
<span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Get</span><span class="nv"> </span><span class="s">the</span><span class="nv"> </span><span class="s">dependencies</span><span class="nv"> </span><span class="s">(via</span><span class="nv"> </span><span class="s">npm)</span><span class="nv"> </span><span class="s">and</span><span class="nv"> </span><span class="s">cache</span><span class="nv"> </span><span class="s">them."</span>
<span class="na">inputs</span><span class="pi">:</span> <span class="c1"># Custom input for the action</span>
  <span class="na">to-cache</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Whether</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">cache</span><span class="nv"> </span><span class="s">dependencies</span><span class="nv"> </span><span class="s">or</span><span class="nv"> </span><span class="s">not"</span>
    <span class="na">required</span><span class="pi">:</span> <span class="kc">false</span>
    <span class="na">default</span><span class="pi">:</span> <span class="s2">"</span><span class="s">true"</span>
<span class="na">outputs</span><span class="pi">:</span> <span class="c1"># Custom output for the action</span>
  <span class="na">used-cache</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Whether</span><span class="nv"> </span><span class="s">cache</span><span class="nv"> </span><span class="s">was</span><span class="nv"> </span><span class="s">used</span><span class="nv"> </span><span class="s">or</span><span class="nv"> </span><span class="s">not"</span>
    <span class="na">value</span><span class="pi">:</span> <span class="s">$</span>

<span class="c1"># runs and using are compulsory</span>
<span class="na">runs</span><span class="pi">:</span>
  <span class="na">using</span><span class="pi">:</span> <span class="s2">"</span><span class="s">composite"</span>
  <span class="na">steps</span><span class="pi">:</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Cache dependencies</span>
      <span class="na">if</span><span class="pi">:</span> <span class="s">inputs.to-cache == 'true'</span>
      <span class="na">id</span><span class="pi">:</span> <span class="s">cache</span>
      <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/cache@v3</span>
      <span class="na">with</span><span class="pi">:</span>
        <span class="na">path</span><span class="pi">:</span> <span class="s">node_modules</span>
        <span class="na">key</span><span class="pi">:</span> <span class="s">deps-node-modules-$</span>
    <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Install dependencies</span>
      <span class="na">id</span><span class="pi">:</span> <span class="s">install-deps</span>
      <span class="na">if</span><span class="pi">:</span> <span class="s">steps.cache.outputs.cache-hit != 'true' || inputs.to-cache != 'true'</span>
      <span class="c1"># shell required if using 'run' key</span>
      <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
        <span class="s">npm ci</span>
        <span class="s">echo "cache-output=$" &gt;&gt; $GITHUB_OUTPUT</span>
      <span class="na">shell</span><span class="pi">:</span> <span class="s">bash</span>
</code></pre></div></div> <h3 id="example-using-custom-action-at-workflow-yml">Example (Using custom Action at workflow yml)</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">jobs</span><span class="pi">:</span>
  <span class="na">lint</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Load and cache dependencies</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">cache-deps</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">./.github/actions/cached-deps</span> <span class="c1">#gh-actions will look for action.yml</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">to-cache</span><span class="pi">:</span> <span class="s2">"</span><span class="s">false"</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output Information</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">echo "Cached used? $"</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Lint code</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">npm run lint</span>
</code></pre></div></div> <h2 id="javascript-actions">JavaScript Actions</h2> <ul> <li>Contains action.yml and some_name.js within <code class="language-plaintext highlighter-rouge">.github/&lt;folder_name&gt;/&lt;action_name&gt;/</code> directory</li> <li>Requires addition npm libraries <ul> <li><code class="language-plaintext highlighter-rouge">cd</code> to the directory where the action files are located</li> <li><code class="language-plaintext highlighter-rouge">npm init -y</code> <ul> <li>Requires nodeJS installed in your system</li> </ul> </li> <li><code class="language-plaintext highlighter-rouge">npm install @actions/core @actions/github @actions/exec</code></li> </ul> </li> </ul> <blockquote> <p>💡 Ensure all files in node_modules in the directory is not gitignored</p> </blockquote> <h3 id="actionyml">action.yml</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Deploy</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">AWS</span><span class="nv"> </span><span class="s">S3"</span>
<span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Deploy</span><span class="nv"> </span><span class="s">static</span><span class="nv"> </span><span class="s">website</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">AWS</span><span class="nv"> </span><span class="s">S3"</span>
<span class="na">inputs</span><span class="pi">:</span>
  <span class="na">bucket</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">S3</span><span class="nv"> </span><span class="s">bucket</span><span class="nv"> </span><span class="s">name"</span>
    <span class="na">required</span><span class="pi">:</span> <span class="kc">true</span>
  <span class="na">bucket-region</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">S3</span><span class="nv"> </span><span class="s">bucket</span><span class="nv"> </span><span class="s">region"</span>
    <span class="na">required</span><span class="pi">:</span> <span class="kc">false</span>
    <span class="na">default</span><span class="pi">:</span> <span class="s2">"</span><span class="s">ap-southeast-1"</span>
  <span class="na">dist-folder</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Folder</span><span class="nv"> </span><span class="s">containing</span><span class="nv"> </span><span class="s">deployable</span><span class="nv"> </span><span class="s">files."</span>
    <span class="na">required</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">outputs</span><span class="pi">:</span>
  <span class="na">website-url</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">URL</span><span class="nv"> </span><span class="s">of</span><span class="nv"> </span><span class="s">deployed</span><span class="nv"> </span><span class="s">site"</span>
    <span class="c1"># NOTE: WE DO NOT HAVE VALUES HERE.</span>
    <span class="c1"># HANDLED IN THE JS FILE</span>

<span class="na">runs</span><span class="pi">:</span>
  <span class="na">using</span><span class="pi">:</span> <span class="s2">"</span><span class="s">node16"</span> <span class="c1"># Tells gh that this is a JS Action</span>
  <span class="na">main</span><span class="pi">:</span> <span class="s2">"</span><span class="s">main.js"</span> <span class="c1"># File the gh action is going to use</span>
</code></pre></div></div> <h3 id="mainjs">main.js</h3> <div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">const</span> <span class="nx">core</span> <span class="o">=</span> <span class="nf">require</span><span class="p">(</span><span class="dl">"</span><span class="s2">@actions/core</span><span class="dl">"</span><span class="p">);</span>
<span class="kd">const</span> <span class="nx">github</span> <span class="o">=</span> <span class="nf">require</span><span class="p">(</span><span class="dl">"</span><span class="s2">@actions/github</span><span class="dl">"</span><span class="p">);</span>
<span class="kd">const</span> <span class="nx">exec</span> <span class="o">=</span> <span class="nf">require</span><span class="p">(</span><span class="dl">"</span><span class="s2">@actions/exec</span><span class="dl">"</span><span class="p">);</span>

<span class="kd">function</span> <span class="nf">run</span><span class="p">()</span> <span class="p">{</span>
  <span class="nx">core</span><span class="p">.</span><span class="nf">notice</span><span class="p">(</span><span class="dl">"</span><span class="s2">Hello from custom JavaScript Action</span><span class="dl">"</span><span class="p">);</span>
  <span class="c1">// Get input vals</span>
  <span class="kd">const</span> <span class="nx">bucket</span> <span class="o">=</span> <span class="nx">core</span><span class="p">.</span><span class="nf">getInput</span><span class="p">(</span><span class="dl">"</span><span class="s2">bucket</span><span class="dl">"</span><span class="p">,</span> <span class="p">{</span> <span class="na">required</span><span class="p">:</span> <span class="kc">true</span> <span class="p">});</span>
  <span class="kd">const</span> <span class="nx">bucketRegion</span> <span class="o">=</span> <span class="nx">core</span><span class="p">.</span><span class="nf">getInput</span><span class="p">(</span><span class="dl">"</span><span class="s2">bucket-region</span><span class="dl">"</span><span class="p">,</span> <span class="p">{</span> <span class="na">required</span><span class="p">:</span> <span class="kc">false</span> <span class="p">});</span>
  <span class="kd">const</span> <span class="nx">distFolder</span> <span class="o">=</span> <span class="nx">core</span><span class="p">.</span><span class="nf">getInput</span><span class="p">(</span><span class="dl">"</span><span class="s2">dist-folder</span><span class="dl">"</span><span class="p">,</span> <span class="p">{</span> <span class="na">required</span><span class="p">:</span> <span class="kc">true</span> <span class="p">});</span>

  <span class="c1">// Upload to s3</span>
  <span class="kd">const</span> <span class="nx">s3uri</span> <span class="o">=</span> <span class="s2">`s3://</span><span class="p">${</span><span class="nx">bucket</span><span class="p">}</span><span class="s2">`</span><span class="p">;</span>
  <span class="nx">exec</span><span class="p">.</span><span class="nf">exec</span><span class="p">(</span><span class="s2">`aws s3 sync </span><span class="p">${</span><span class="nx">distFolder</span><span class="p">}</span><span class="s2"> </span><span class="p">${</span><span class="nx">s3uri</span><span class="p">}</span><span class="s2"> --region </span><span class="p">${</span><span class="nx">bucketRegion</span><span class="p">}</span><span class="s2">`</span><span class="p">);</span>

  <span class="c1">// Return URL</span>
  <span class="kd">const</span> <span class="nx">websiteUrl</span> <span class="o">=</span> <span class="s2">`http://</span><span class="p">${</span><span class="nx">bucket</span><span class="p">}</span><span class="s2">.s3-website-</span><span class="p">${</span><span class="nx">bucketRegion</span><span class="p">}</span><span class="s2">.amazonaws.com`</span><span class="p">;</span>
  <span class="nx">core</span><span class="p">.</span><span class="nf">setOutput</span><span class="p">(</span><span class="dl">"</span><span class="s2">website-url</span><span class="dl">"</span><span class="p">,</span> <span class="nx">websiteUrl</span><span class="p">);</span>
<span class="p">}</span>

<span class="nf">run</span><span class="p">();</span>
</code></pre></div></div> <h3 id="workflow-1">workflow</h3> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">jobs</span><span class="pi">:</span>
  <span class="na">lint</span><span class="pi">:</span> <span class="s">...</span>
  <span class="na">test</span><span class="pi">:</span> <span class="s">...</span>
  <span class="na">build</span><span class="pi">:</span> <span class="s">...</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">needs</span><span class="pi">:</span> <span class="s">build</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v3</span> <span class="c1"># REQUIRED for local JS Action</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get build artifacts</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/download-artifact@v3</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">name</span><span class="pi">:</span> <span class="s">dist-files</span>
          <span class="na">path</span><span class="pi">:</span> <span class="s">./dist</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output contents</span>
        <span class="na">run</span><span class="pi">:</span> <span class="s">ls</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Deploy site</span>
        <span class="na">id</span><span class="pi">:</span> <span class="s">deploy</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">./.github/actions/deploy-s3-javascript</span>
        <span class="na">env</span><span class="pi">:</span>
          <span class="na">AWS_ACCESS_KEY_ID</span><span class="pi">:</span> <span class="s">$</span>
          <span class="na">AWS_SECRET_ACCESS_KEY</span><span class="pi">:</span> <span class="s">$</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">bucket</span><span class="pi">:</span> <span class="s">jk-gha-custom-hosting</span>
          <span class="na">dist-folder</span><span class="pi">:</span> <span class="s">./dist</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Output Info</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">echo 'URL: $'</span>
</code></pre></div></div> <blockquote> <p>💡 JS Custom action requires user to do <code class="language-plaintext highlighter-rouge">actions/checkout</code> if the action is a local custom action</p> </blockquote> <h2 id="docker-action">Docker Action</h2> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Deploy</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">AWS</span><span class="nv"> </span><span class="s">S3</span><span class="nv"> </span><span class="s">Docker"</span>
<span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Deploy</span><span class="nv"> </span><span class="s">static</span><span class="nv"> </span><span class="s">website</span><span class="nv"> </span><span class="s">to</span><span class="nv"> </span><span class="s">AWS</span><span class="nv"> </span><span class="s">S3</span><span class="nv"> </span><span class="s">via</span><span class="nv"> </span><span class="s">docker"</span>
<span class="na">inputs</span><span class="pi">:</span>
  <span class="na">bucket</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">S3</span><span class="nv"> </span><span class="s">bucket</span><span class="nv"> </span><span class="s">name"</span>
    <span class="na">required</span><span class="pi">:</span> <span class="kc">true</span>
  <span class="na">bucket-region</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">S3</span><span class="nv"> </span><span class="s">bucket</span><span class="nv"> </span><span class="s">region"</span>
    <span class="na">required</span><span class="pi">:</span> <span class="kc">false</span>
    <span class="na">default</span><span class="pi">:</span> <span class="s2">"</span><span class="s">ap-southeast-1"</span>
  <span class="na">dist-folder</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Folder</span><span class="nv"> </span><span class="s">containing</span><span class="nv"> </span><span class="s">deployable</span><span class="nv"> </span><span class="s">files."</span>
    <span class="na">required</span><span class="pi">:</span> <span class="kc">true</span>
<span class="na">outputs</span><span class="pi">:</span>
  <span class="na">website-url</span><span class="pi">:</span>
    <span class="na">description</span><span class="pi">:</span> <span class="s2">"</span><span class="s">URL</span><span class="nv"> </span><span class="s">of</span><span class="nv"> </span><span class="s">deployed</span><span class="nv"> </span><span class="s">site"</span>

<span class="na">runs</span><span class="pi">:</span>
  <span class="na">using</span><span class="pi">:</span> <span class="s2">"</span><span class="s">docker"</span>
  <span class="na">image</span><span class="pi">:</span> <span class="s2">"</span><span class="s">Dockerfile"</span>
</code></pre></div></div> <blockquote> <p>💡 gh generates ENV*VAR for the inputs with prefix <code class="language-plaintext highlighter-rouge">INPUT*\*</code>. [SEE BELOW]</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bucket</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">INPUT_BUCKET</span><span class="sh">'</span><span class="p">]</span>
<span class="n">bucket_region</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">INPUT_BUCKET-REGION</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dist_folder</span> <span class="o">=</span> <span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">INPUT_DIST-FOLDER</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <blockquote> <p>💡 outputs are handled by using the print of the language. E.g. python print() [SEE BELOW]</p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">GITHUB_OUTPUT</span><span class="sh">'</span><span class="p">],</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">gh_output</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">website-url=</span><span class="si">{</span><span class="n">website_url</span><span class="si">}</span><span class="sh">'</span><span class="p">,</span> <span class="nb">file</span><span class="o">=</span><span class="n">gh_output</span><span class="p">)</span>
</code></pre></div></div> <h1 id="security-of-gh-actions">Security of gh actions</h1> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/20-480.webp 480w,/assets/img/2025-01-13-github-actions/20-800.webp 800w,/assets/img/2025-01-13-github-actions/20-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/20.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="script-injections">Script Injections</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/21-480.webp 480w,/assets/img/2025-01-13-github-actions/21-800.webp 800w,/assets/img/2025-01-13-github-actions/21-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/21.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li>Be careful of assignment of variables in <code class="language-plaintext highlighter-rouge">run</code> <ul> <li><code class="language-plaintext highlighter-rouge">issue_title="$”</code> can lead to script injection by passing in: <code class="language-plaintext highlighter-rouge">a”; echo $AWS_ACCESS_KEY_ID</code> - This results in - <code class="language-plaintext highlighter-rouge">issue_title="a"</code> - <code class="language-plaintext highlighter-rouge">echo $AWS_ACCESS_KEY_ID</code> - which will give the details</li> <li>Solve this by using a ENV_VAR instead</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/22-480.webp 480w,/assets/img/2025-01-13-github-actions/22-800.webp 800w,/assets/img/2025-01-13-github-actions/22-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/22.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="actions">Actions</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-01-13-github-actions/23-480.webp 480w,/assets/img/2025-01-13-github-actions/23-800.webp 800w,/assets/img/2025-01-13-github-actions/23-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-01-13-github-actions/23.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="permission">Permission</h2> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">Label Issues (Permissions Example)</span>
<span class="na">on</span><span class="pi">:</span>
  <span class="na">issues</span><span class="pi">:</span>
    <span class="na">types</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">opened</span>
<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">assign-label</span><span class="pi">:</span>
    <span class="na">permissions</span><span class="pi">:</span> <span class="c1"># RESTRICT PERMISSION. DEFAULT: FULL ACCESS ON EVERYTHING.</span>
      <span class="na">issues</span><span class="pi">:</span> <span class="s">write</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">ubuntu-latest</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Assign label</span>
        <span class="na">if</span><span class="pi">:</span> <span class="s">contains(github.event.issue.title, 'bug')</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">curl -X POST \</span>
          <span class="s">--url https://api.github.com/repos/$/issues/$/labels \</span>
          <span class="s">-H 'authorization: Bearer $' \</span>
          <span class="s">-H 'content-type: application/json' \</span>
          <span class="s">-d '{</span>
              <span class="s">"labels": ["bug"]</span>
            <span class="s">}' \</span>
          <span class="s">--fail</span>
</code></pre></div></div> <h3 id="secretsgithub_token">secrets.GITHUB_TOKEN</h3> <p>Token generated by github for the github API</p> <ul> <li>Gets revoked by the end of the job</li> <li>Permissions set in the yml will be the permission assigned to the GITHUB_TOKEN.</li> </ul> <h2 id="managing-more-permissions">Managing more permissions</h2> <p>Repository → Setting → Action → General</p> <h2 id="managing-secret-keys-for-3rd-party-platforms">Managing Secret Keys for 3rd-party platforms</h2> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Deploy site</span>
  <span class="na">id</span><span class="pi">:</span> <span class="s">deploy</span>
  <span class="na">uses</span><span class="pi">:</span> <span class="s">./.github/actions/deploy-s3-javascript</span>
  <span class="na">env</span><span class="pi">:</span>
    <span class="na">AWS_ACCESS_KEY_ID</span><span class="pi">:</span> <span class="s">$</span>
    <span class="na">AWS_SECRET_ACCESS_KEY</span><span class="pi">:</span> <span class="s">$</span>
</code></pre></div></div> <ul> <li>Information like <code class="language-plaintext highlighter-rouge">AWS_ACCESS_KEY_ID</code> and <code class="language-plaintext highlighter-rouge">AWS_SECRET_ACCESS_KEY</code> are saved in the github action secrets <ul> <li>But still vulnerable to script injections</li> </ul> </li> <li>OpenID Connect can help to make it more secure <ul> <li>Dynamically gets credentials</li> <li>Requires setting up AWS IAM Role for this</li> <li>Uses <code class="language-plaintext highlighter-rouge">aws-actions/configure-aws-credentials</code></li> <li>Do not need the <code class="language-plaintext highlighter-rouge">env</code> anymore</li> </ul> </li> </ul> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">job</span><span class="pi">:</span>
  <span class="na">deploy</span><span class="pi">:</span>
    <span class="na">permissions</span><span class="pi">:</span>
      <span class="na">id-token</span><span class="pi">:</span> <span class="s">write</span> <span class="c1"># REQUIRED as default GITHUB_TOKEN is set to None for this</span>
      <span class="na">contents</span><span class="pi">:</span> <span class="s">read</span>
    <span class="s">...</span>
    <span class="na">steps</span><span class="pi">:</span>
      <span class="c1"># Do something above</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Get AWS Permissions</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">aws-actions/configure-aws-credentials@v1</span>
        <span class="na">with</span><span class="pi">:</span>
          <span class="na">role-to-assume</span><span class="pi">:</span> <span class="s">arn:aws:iam::...</span>
          <span class="na">aws-region</span><span class="pi">:</span> <span class="s">...</span>
      <span class="s">...</span>
</code></pre></div></div>]]></content><author><name></name></author><category term="learning"/><category term="data_engineering"/><category term="github_actions"/><category term="cicd"/><summary type="html"><![CDATA[Notes on Github Actions]]></summary></entry><entry><title type="html">Profiling my favourite songs on Spotify through clustering</title><link href="https://jkwd.github.io/blog/2019/profiling-my-favourite-songs-on-spotify-through-clustering/" rel="alternate" type="text/html" title="Profiling my favourite songs on Spotify through clustering"/><published>2019-02-17T00:00:00+00:00</published><updated>2019-02-17T00:00:00+00:00</updated><id>https://jkwd.github.io/blog/2019/profiling-my-favourite-songs-on-spotify-through-clustering</id><content type="html" xml:base="https://jkwd.github.io/blog/2019/profiling-my-favourite-songs-on-spotify-through-clustering/"><![CDATA[<figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/1-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/1-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Music plays an integral part of most of our lives. It is the common language that helps us express ourselves when no words could describe how we feel. Music also helps us set the mood. It affects our soul and our emotion, making us feel happy, sad or energetic. We will probably be playing songs to sing along during our long drives, or listening to upbeat songs during our gym sessions.</p> <p>Many of us have specific tastes in the music we listen to and it may change from time to time. This got me thinking…</p> <p>Have my taste in music changed over the years? If so, when did the changes occur? Based on my recent taste in music, what type(s) of music am I listening to now? Thanks to Spotify API, I am able to extract and explore the songs I enjoy listening to — the ones that made me click that heart icon.</p> <h2 id="setup">Setup</h2> <p>To get the data from the Spotify API, we will need to do an initial setup with the following steps:</p> <ol> <li>Login to <a href="https://developer.spotify.com/">Spotify for Developers</a> and create an app.</li> <li>From the application dashboard page, select edit settings and set Redirect URIs as <code class="language-plaintext highlighter-rouge">http://localhost:8888</code>.</li> <li>Take note of the Client ID and the Client Secret.</li> </ol> <h2 id="gathering-data">Gathering data</h2> <p>We can use <a href="https://spotipy.readthedocs.io/en/latest/">Spotipy</a>, a Python library for the Spotify Web API, to get the relevant data. To get the songs, we need to generate an authorization token.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">spotipy</span>
<span class="kn">import</span> <span class="n">spotipy.util</span> <span class="k">as</span> <span class="n">util</span>
<span class="kn">from</span> <span class="n">spotipy.oauth2</span> <span class="kn">import</span> <span class="n">SpotifyClientCredentials</span>
<span class="n">cid</span> <span class="o">=</span> <span class="sh">'</span><span class="s">&lt;INSERT CLIENT ID&gt;</span><span class="sh">'</span>
<span class="n">secret</span> <span class="o">=</span> <span class="sh">'</span><span class="s">&lt;INSERT CLIENT SECRET&gt;</span><span class="sh">'</span>
<span class="n">username</span> <span class="o">=</span> <span class="sh">""</span>
<span class="n">client_credentials_manager</span> <span class="o">=</span> <span class="nc">SpotifyClientCredentials</span><span class="p">(</span><span class="n">client_id</span><span class="o">=</span><span class="n">cid</span><span class="p">,</span> <span class="n">client_secret</span><span class="o">=</span><span class="n">secret</span><span class="p">)</span>
<span class="n">sp</span> <span class="o">=</span> <span class="n">spotipy</span><span class="p">.</span><span class="nc">Spotify</span><span class="p">(</span><span class="n">client_credentials_manager</span><span class="o">=</span><span class="n">client_credentials_manager</span><span class="p">)</span>
<span class="c1"># Get read access to your library
</span><span class="n">scope</span> <span class="o">=</span> <span class="sh">'</span><span class="s">user-library-read</span><span class="sh">'</span>
<span class="n">token</span> <span class="o">=</span> <span class="n">util</span><span class="p">.</span><span class="nf">prompt_for_user_token</span><span class="p">(</span><span class="n">username</span><span class="p">,</span> <span class="n">scope</span><span class="p">)</span>
<span class="k">if</span> <span class="n">token</span><span class="p">:</span>
    <span class="n">sp</span> <span class="o">=</span> <span class="n">spotipy</span><span class="p">.</span><span class="nc">Spotify</span><span class="p">(</span><span class="n">auth</span><span class="o">=</span><span class="n">token</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">Can</span><span class="sh">'</span><span class="s">t get token for</span><span class="sh">"</span><span class="p">,</span> <span class="n">username</span><span class="p">)</span>
</code></pre></div></div> <p>There are two APIs, current_user_saved_tracks and audio_features, to get the title, artist, time song was added, and features such as acousticness, danceability and instrumentalness. These features will help us in understanding our playlist better.</p> <p>Some of the description to the features are in the table below:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/2-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/2-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/2-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>To view the full features of a song, you may view this <a href="https://developer.spotify.com/documentation/web-api/reference/get-audio-features">link</a>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df_saved_tracks</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="n">track_list</span> <span class="o">=</span> <span class="sh">''</span>
<span class="n">added_ts_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">artist_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">title_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">more_songs</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">offset_index</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">more_songs</span><span class="p">:</span>
    <span class="n">songs</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="nf">current_user_saved_tracks</span><span class="p">(</span><span class="n">offset</span><span class="o">=</span><span class="n">offset_index</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">song</span> <span class="ow">in</span> <span class="n">songs</span><span class="p">[</span><span class="sh">'</span><span class="s">items</span><span class="sh">'</span><span class="p">]:</span>
        <span class="c1">#join track ids to a string for audio_features function
</span>        <span class="n">track_list</span> <span class="o">+=</span> <span class="n">song</span><span class="p">[</span><span class="sh">'</span><span class="s">track</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">+</span><span class="sh">'</span><span class="s">,</span><span class="sh">'</span>
        <span class="c1">#get the time when the song was added
</span>        <span class="n">added_ts_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">song</span><span class="p">[</span><span class="sh">'</span><span class="s">added_at</span><span class="sh">'</span><span class="p">])</span>
        <span class="c1">#get the title of the song
</span>        <span class="n">title_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">song</span><span class="p">[</span><span class="sh">'</span><span class="s">track</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">])</span>
        <span class="c1">#get all the artists in the song
</span>        <span class="n">artists</span> <span class="o">=</span> <span class="n">song</span><span class="p">[</span><span class="sh">'</span><span class="s">track</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">artists</span><span class="sh">'</span><span class="p">]</span>
        <span class="n">artists_name</span> <span class="o">=</span> <span class="sh">''</span>
        <span class="k">for</span> <span class="n">artist</span> <span class="ow">in</span> <span class="n">artists</span><span class="p">:</span>
            <span class="n">artists_name</span> <span class="o">+=</span> <span class="n">artist</span><span class="p">[</span><span class="sh">'</span><span class="s">name</span><span class="sh">'</span><span class="p">]</span>  <span class="o">+</span> <span class="sh">'</span><span class="s">,</span><span class="sh">'</span>
        <span class="n">artist_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">artists_name</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="c1">#get the track features and append into a dataframe
</span>    <span class="n">track_features</span> <span class="o">=</span> <span class="n">sp</span><span class="p">.</span><span class="nf">audio_features</span><span class="p">(</span><span class="n">track_list</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">track_features</span><span class="p">)</span>
    <span class="n">df_saved_tracks</span> <span class="o">=</span> <span class="n">df_saved_tracks</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">df_temp</span><span class="p">)</span>
    <span class="n">track_list</span> <span class="o">=</span> <span class="sh">''</span>
    <span class="k">if</span> <span class="n">songs</span><span class="p">[</span><span class="sh">'</span><span class="s">next</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">None</span><span class="p">:</span>
        <span class="c1"># no more songs in playlist
</span>        <span class="n">more_songs</span> <span class="o">=</span> <span class="bp">False</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># get the next n songs
</span>        <span class="n">offset_index</span> <span class="o">+=</span> <span class="n">songs</span><span class="p">[</span><span class="sh">'</span><span class="s">limit</span><span class="sh">'</span><span class="p">]</span>
<span class="c1">#include timestamp added, title and artists of a song
</span><span class="n">df_saved_tracks</span><span class="p">[</span><span class="sh">'</span><span class="s">added_at</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">added_ts_list</span>
<span class="n">df_saved_tracks</span><span class="p">[</span><span class="sh">'</span><span class="s">song_title</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">title_list</span>
<span class="n">df_saved_tracks</span><span class="p">[</span><span class="sh">'</span><span class="s">artists</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">artist_list</span>
</code></pre></div></div> <p>Here is a sample of the data set obtained.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/3-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/3-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/3-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h2 id="did-my-taste-in-music-change">Did my taste in music change?</h2> <p>After obtaining the data, it is time to find out how the features change across time. We can group the songs by its added year and month, get the average for each feature over time and visualize it.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/4-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/4-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/4-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The line graph was separated by year to make it more bite-size. Speechiness (in violet) is the most stable closer to 0 across the years. This indicates that I generally listen to songs which are less rap. Acousticness (in blue) is fluctuating which means that I have a mix of acoustic and non-acoustic songs over time.</p> <p>What interests me the most was instrumentalness (in green). For the year of 2015 and 2016, it was stable closer to 0. However, from 2017 onward, instrumentalness started to fluctuate. This is probably the indication that my music taste changed from 2017. We can filter our data to songs which were added from 2017.</p> <h2 id="what-types-of-songs-am-i-listening-to">What types of songs am I listening to?</h2> <h3 id="clustering">Clustering</h3> <p>Based on the chart above, I know that I am listening to more instrumental songs. But is it instrumental dance kind of songs? Or more classical songs? What about the others? What is my current taste in music? We could group songs with similar characteristics together, and profile each cluster. One type of clustering method is <a href="https://en.wikipedia.org/wiki/K-means_clustering">K-means Clustering</a> which is what I will be using to analyse my songs.</p> <p>For clustering, we want the points in the same cluster to be as close as possible. We also want the distance between clusters to be far from each other as possible. This makes each cluster look compact while being spaced out from each other.</p> <p>Here is a visualization of what clustering looks like for 4 clusters. The green dot represents each cluster centroid (centre of the cluster).</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/5.gif" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/5.gif" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">K-means clustering taken from http://shabal.in/visuals/kmeans/6.html</figcaption> </figure> <p>Because clustering relies on distance, the scale of our data will affect the results. For example, if we want to cluster by height, from 1.5m to 1.9m, and weight, from 60kg to 80kg. Thus, the points spreads across the height axis by 0.4 and the weight by 20. This means that weight will be dominant in determining the clusters.</p> <p>We can standardize the range of the data such that the features will influence the result.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cluster_features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">acousticness</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">danceability</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">instrumentalness</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">energy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">speechiness</span><span class="sh">'</span><span class="p">]</span>
<span class="n">df_cluster</span> <span class="o">=</span> <span class="n">df_recent</span><span class="p">[</span><span class="n">cluster_features</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">df_cluster</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="nc">StandardScaler</span><span class="p">()</span>
<span class="n">scaler</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">scaler</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div> <p>After getting an idea of what clustering does, how many types/groups of songs do we listen to? One way is to make an educated guess based on your own knowledge. If you listen to all types of music from edm to hip hop to jazz and many more, you can give a higher number like… 7 maybe? Because K-means clustering requires us to specify the number of clusters we want, we can set k=7, where k is the number of clusters.</p> <p>Another way is to use the help of the elbow method to determine the number of clusters. In the elbow method, we can perform clustering for a range of set cluster numbers, e.g. k=1, k=2, …, k=9, k=10. For each k, we will take each point and measure its squared distance to their cluster centroid, and sum them up. This is called the sum of squared distances (SSD). SSD measures how close each points are to the cluster centroid. Therefore, the smaller the SSD, the closer the points in the same cluster are.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ss_dist</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">K</span> <span class="o">=</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">K</span><span class="p">:</span>
    <span class="n">km</span> <span class="o">=</span> <span class="nc">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="sh">'</span><span class="s">k-means++</span><span class="sh">'</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
    <span class="n">km</span> <span class="o">=</span> <span class="n">km</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">ss_dist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">km</span><span class="p">.</span><span class="n">inertia_</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">K</span><span class="p">,</span> <span class="n">ss_dist</span><span class="p">,</span> <span class="sh">'</span><span class="s">bx-</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Sum of squared distances</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">Elbow Method For Optimal k</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p>So if we plot the SSD for each k we will get curved line as shown below:</p> <div class="col-sm-9 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/6-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/6-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/6-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>From the plot above, as k increases, SSD decreases. This is makes sense because points may have a closer cluster to be assigned to, resulting in a lower SSD.</p> <p>Earlier, I mentioned that we want the points in each cluster to be as close as possible. However, we cannot choose k=10 because it is the lowest. Imagine this. If we choose k=N, where N is the number of songs, we are having each song as its own cluster and thus SSD will be 0. This is because the cluster centroid of each point is the point itself.</p> <p>Instead, we are going to choose k such that if we add another cluster, SSD decreases slightly. This is known as the elbow method. If we think of the curve as our arm, we get a steep slope at the beginning which suddenly becomes gentle midway. This gives it its “elbow” shape.</p> <p>Based on the elbow method, the number of clusters recommended is 4 because the line became gentle from k=4 to k=5. However, I’ve also played around with k=5 and found that I like the clusters given. Therefore, in this post I will be sharing the results I got for k=5 instead.</p> <h2 id="cluster-visualization">Cluster Visualization</h2> <p>Great we finally have our cluster! So how does our cluster look like? Unfortunately, at this we are unable to view it yet. This is because our clusters are formed using 5 features. If you think of each feature as a dimension, you get 5-D. As we can view images up to 3-D, we will need to perform a technique called <a href="https://en.wikipedia.org/wiki/Dimensionality_reduction">dimension reduction</a>. This allows us to reduce from 5-D to any dimensions lower.</p> <p>To try and explain it as intuitively as possible, dimension reduction aims to make a low dimensional set of features from a higher dimension while preserving as much information as possible. If you wish to get a better understanding of what it does you may watch this <a href="https://www.youtube.com/watch?v=FgakZw6K1QQ">video</a> about Principal Component Analysis(PCA), which is one of the methods in dimension reduction.</p> <p>Let’s see how much data is preserved if we use PCA to reduce the dimension.</p> <div class="col-sm-9 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/7-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/7-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/7-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>The blue bar shows how much information each principal component (PC) contributes to the data. The first PC contributes 40% of information about the data. The second and third contributes 20% each. The red line shows the cumulative information of the data by the PCs. By reducing from 5 dimensions to 2, 60% information of the data is preserved. Likewise if we were to reduce to 3 dimensions, 80% information of the data is preserved.</p> <p>Now let’s see how our clusters look like on a 2-D and 3-D scatter plot.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/8-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/8-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/8-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/9-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/9-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/9-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>The points in the 2-D scatter plot overlaps with each other and may not look like the clustering was done well. However if we were to view it from a 3-D perspective, we can see the clusters better.</p> <p>Let’s try another method called t-Distributed Stochastic Neighbor Embedding(t-SNE). t-SNE performs well for visualizing high dimension data. For more details, you may read this <a href="https://www.datacamp.com/tutorial/introduction-t-sne">tutorial</a> by datacamp.</p> <div class="col-sm-9 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/10-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/10-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/10-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <p>In this case, a 2-D t-SNE scatter plot is able to visualize the 5 clusters nicely. We can also roughly tell that cluster 3 is the biggest cluster and cluster 0 or 1 is the smallest. Let’s see how the clusters are distributed using a bar chart.</p> <div class="col-sm-9 mx-auto"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/11-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/11-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/11-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <h2 id="cluster-profiling">Cluster Profiling</h2> <p>Now, we can make sense of what the characteristics of the different clusters are. Let’s compare the distribution of features across clusters.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set binning intervals of 0.1
</span><span class="n">bins</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># create subplots for number of clusters(Rows) and features(Cols)
</span><span class="n">num_features</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">cluster_features</span><span class="p">)</span>
<span class="n">f</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span>
                       <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">sharex</span><span class="o">=</span><span class="sh">'</span><span class="s">col</span><span class="sh">'</span>
<span class="n">row</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">np</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">df_recent</span><span class="p">[</span><span class="sh">'</span><span class="s">cluster</span><span class="sh">'</span><span class="p">].</span><span class="nf">unique</span><span class="p">()):</span>
    <span class="n">df_cluster</span> <span class="o">=</span> <span class="n">df_recent</span><span class="p">[</span><span class="n">df_recent</span><span class="p">[</span><span class="sh">'</span><span class="s">cluster</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="n">cluster</span><span class="p">]</span>
    <span class="n">col</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">cluster_features</span><span class="p">:</span>
        <span class="n">rec_grp</span> <span class="o">=</span> <span class="n">df_recent</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nf">cut</span><span class="p">(</span><span class="n">df_recent</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">bins</span><span class="p">)).</span><span class="nf">size</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">)</span>
        <span class="n">cluster_grp</span> <span class="o">=</span> <span class="n">df_cluster</span><span class="p">.</span><span class="nf">groupby</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nf">cut</span><span class="p">(</span><span class="n">df_cluster</span><span class="p">[</span><span class="n">feature</span><span class="p">],</span> <span class="n">bins</span><span class="p">)).</span><span class="nf">size</span><span class="p">().</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">)</span>

        <span class="n">sns</span><span class="p">.</span><span class="nf">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">rec_grp</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">grey</span><span class="sh">'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">])</span>
        <span class="n">sns</span><span class="p">.</span><span class="nf">barplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">cluster_grp</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">feature</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">count</span><span class="sh">'</span><span class="p">,</span>
                    <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">])</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">].</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">''</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">].</span><span class="nf">set_xticklabels</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">col</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">].</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sh">''</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">row</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">axes</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">col</span><span class="p">].</span><span class="nf">set_title</span><span class="p">(</span><span class="n">feature</span><span class="p">)</span>
        <span class="n">col</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">row</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="n">f</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="sh">'</span><span class="s">Profile for each clusters</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/12-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/12-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/12-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>Each Row represents the cluster, 0 to 4, and the each Column represents the feature. The grey bar represents the distribution of the feature. This allows us to get a rough idea of the distribution of the feature. The red bar represents the distribution of the feature in that cluster which is used to compare against the other clusters.</p> <p>When we look at the distribution of each cluster we can see that each cluster is high or low in certain features. This is identified by whether the red bar is on the right(high) or left(low) with respect to the grey bar. From these characteristics we can profile them and even come up with a cluster identity.</p> <p>Cluster 0 (Instrumental): High instrumentalness. Low speechiness.</p> <p>Cluster 1 (Lyrical): High danceability, energy, speechiness. Low acousticness, instrumentalness.</p> <p>Cluster 2 (Chill vibes): High danceability. Low energy, instrumentalness, speechiness.</p> <p>Cluster 3 (Dance): High danceability, energy. Low acousticness, instrumentalness, speechiness.</p> <p>Cluster 4 (Wind down): High acousticness. Low danceability, instrumnetalness, energy, speechiness.</p> <p>We can also profile by taking the average of the cluster feature and plotting them onto a radar chart. This might be easier to view the differences between all the cluster at a glance.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/13-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/13-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/13-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/13.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/14-480.webp 480w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/14-800.webp 800w,/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/14-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2019-02-17-profiling-my-favourite-songs-on-spotify-through-clustering/14.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>The readings of the radar chart is similar to the profile given above. We can also see that cluster 2 and 4 have a similar stats. The difference is that cluster 2 is more focused on danceability and cluster 4 is more focused on acousticness.</p> <h2 id="cluster-sample">Cluster sample</h2> <p>Let’s see if the songs in each cluster fits the cluster profile. Here are 3 songs in each cluster and you can give it a listen and see if it makes sense:</p> <h3 id="cluster-0-instrumental">Cluster 0 (Instrumental)</h3> <ul> <li>Go Back Home by FKJ</li> <li>Hypnotised by Coldplay</li> <li>Libertango by Astor Piazzolla, Bond</li> </ul> <h3 id="cluster-1-lyrical">Cluster 1 (Lyrical)</h3> <ul> <li>September Rose by Cailin Russo</li> <li>Candlelight by Zhavia Ward</li> <li>BBIBBI by IU</li> </ul> <h3 id="cluster-2-chill-vibes">Cluster 2 (Chill vibes)</h3> <ul> <li>Drop the Game by Flume, Chet Faker</li> <li>Livid by ELIZA</li> <li>Find a Way by Matt Quentin, Rinca Yang</li> </ul> <h3 id="cluster-3-dance">Cluster 3 (Dance)</h3> <ul> <li>Ultralife by Oh Wonder</li> <li>Little Man by The Pb Underground</li> <li>Finesse (Remix) [feat. Cardi B] by Bruno Mars,Cardi B</li> </ul> <h3 id="cluster-4-wind-down">Cluster 4 (Wind down)</h3> <ul> <li>Frozen by Sabrina Claudio</li> <li>Break the Distance 2.0 by Ashton Edminster</li> <li>Someone To Stay by Vancouver Sleep Clinic</li> </ul> <h2 id="conclusion">Conclusion</h2> <p>We first looked at the different features over time and try to figure out if there was a shift in music taste. From the filtered data set, we performed our cluster analysis. We then visualized to get a rough idea of what it looks like and to ensure that the clustering is fine. Finally we plotted the distribution of each feature and profiled them. At the end of the day, we are able to get a better understanding of the type of songs that we like.</p> <p>The collection of data can be found <a href="https://github.com/jkwd/spotify/blob/master/Code/Spotify%20Get%20Data.ipynb">here</a> and the analysis can be found <a href="https://github.com/jkwd/spotify/blob/master/Code/Favourite%20songs%20EDA.ipynb">here</a> on my Github.</p>]]></content><author><name></name></author><category term="project"/><category term="data_science"/><category term="eda"/><category term="clustering"/><summary type="html"><![CDATA[Personal data science EDA project]]></summary></entry></feed>